{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 8s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터셋 준비하기\n",
    "\n",
    "# 훈련셋과 시험셋 로딩\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s 613us/step - loss: 2.2576 - accuracy: 0.1643 - val_loss: 2.2272 - val_accuracy: 0.1633\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 2.2072 - accuracy: 0.1657 - val_loss: 2.1908 - val_accuracy: 0.1800\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 2.1730 - accuracy: 0.1729 - val_loss: 2.1631 - val_accuracy: 0.1867\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 255us/step - loss: 2.1441 - accuracy: 0.1786 - val_loss: 2.1372 - val_accuracy: 0.1867\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 263us/step - loss: 2.1177 - accuracy: 0.1900 - val_loss: 2.1141 - val_accuracy: 0.1867\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 288us/step - loss: 2.0940 - accuracy: 0.2029 - val_loss: 2.0931 - val_accuracy: 0.2033\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 2.0721 - accuracy: 0.2071 - val_loss: 2.0727 - val_accuracy: 0.2067\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 284us/step - loss: 2.0520 - accuracy: 0.2129 - val_loss: 2.0564 - val_accuracy: 0.2067\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 302us/step - loss: 2.0342 - accuracy: 0.2157 - val_loss: 2.0410 - val_accuracy: 0.2033\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 344us/step - loss: 2.0190 - accuracy: 0.2143 - val_loss: 2.0269 - val_accuracy: 0.2067\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 326us/step - loss: 2.0041 - accuracy: 0.2186 - val_loss: 2.0125 - val_accuracy: 0.2100\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 264us/step - loss: 1.9911 - accuracy: 0.2200 - val_loss: 2.0037 - val_accuracy: 0.2100\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 297us/step - loss: 1.9789 - accuracy: 0.2286 - val_loss: 1.9955 - val_accuracy: 0.2100\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 261us/step - loss: 1.9685 - accuracy: 0.2329 - val_loss: 1.9833 - val_accuracy: 0.2067\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.9582 - accuracy: 0.2214 - val_loss: 1.9753 - val_accuracy: 0.2100\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 393us/step - loss: 1.9484 - accuracy: 0.2357 - val_loss: 1.9686 - val_accuracy: 0.2000\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 347us/step - loss: 1.9393 - accuracy: 0.2343 - val_loss: 1.9612 - val_accuracy: 0.2033\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.9309 - accuracy: 0.2314 - val_loss: 1.9537 - val_accuracy: 0.2100\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 321us/step - loss: 1.9232 - accuracy: 0.2286 - val_loss: 1.9452 - val_accuracy: 0.2100\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 291us/step - loss: 1.9156 - accuracy: 0.2386 - val_loss: 1.9392 - val_accuracy: 0.2100\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.9085 - accuracy: 0.2343 - val_loss: 1.9363 - val_accuracy: 0.2100\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 288us/step - loss: 1.9011 - accuracy: 0.2386 - val_loss: 1.9289 - val_accuracy: 0.2033\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 303us/step - loss: 1.8954 - accuracy: 0.2357 - val_loss: 1.9234 - val_accuracy: 0.2100\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 373us/step - loss: 1.8895 - accuracy: 0.2314 - val_loss: 1.9201 - val_accuracy: 0.2067\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 297us/step - loss: 1.8830 - accuracy: 0.2343 - val_loss: 1.9178 - val_accuracy: 0.2167\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 278us/step - loss: 1.8769 - accuracy: 0.2300 - val_loss: 1.9105 - val_accuracy: 0.2167\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.8715 - accuracy: 0.2357 - val_loss: 1.9098 - val_accuracy: 0.2167\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 395us/step - loss: 1.8662 - accuracy: 0.2400 - val_loss: 1.9094 - val_accuracy: 0.2000\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 379us/step - loss: 1.8615 - accuracy: 0.2400 - val_loss: 1.9041 - val_accuracy: 0.1900\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 259us/step - loss: 1.8565 - accuracy: 0.2243 - val_loss: 1.8976 - val_accuracy: 0.2167\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 314us/step - loss: 1.8513 - accuracy: 0.2471 - val_loss: 1.8971 - val_accuracy: 0.1933\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.8463 - accuracy: 0.2371 - val_loss: 1.8925 - val_accuracy: 0.1900\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 298us/step - loss: 1.8423 - accuracy: 0.2229 - val_loss: 1.8874 - val_accuracy: 0.2067\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 384us/step - loss: 1.8382 - accuracy: 0.2371 - val_loss: 1.8808 - val_accuracy: 0.1933\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 386us/step - loss: 1.8335 - accuracy: 0.2471 - val_loss: 1.8836 - val_accuracy: 0.1900\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.8299 - accuracy: 0.2343 - val_loss: 1.8756 - val_accuracy: 0.1967\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.8257 - accuracy: 0.2486 - val_loss: 1.8745 - val_accuracy: 0.1800\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.8220 - accuracy: 0.2371 - val_loss: 1.8700 - val_accuracy: 0.1933\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.8184 - accuracy: 0.2457 - val_loss: 1.8706 - val_accuracy: 0.1767\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 1.8144 - accuracy: 0.2314 - val_loss: 1.8677 - val_accuracy: 0.2000\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 1.8105 - accuracy: 0.2400 - val_loss: 1.8668 - val_accuracy: 0.1833\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 269us/step - loss: 1.8075 - accuracy: 0.2471 - val_loss: 1.8635 - val_accuracy: 0.1800\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 259us/step - loss: 1.8046 - accuracy: 0.2429 - val_loss: 1.8611 - val_accuracy: 0.1700\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 1.8001 - accuracy: 0.2371 - val_loss: 1.8566 - val_accuracy: 0.1967\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.7970 - accuracy: 0.2429 - val_loss: 1.8564 - val_accuracy: 0.1700\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.7939 - accuracy: 0.2271 - val_loss: 1.8528 - val_accuracy: 0.1933\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 245us/step - loss: 1.7913 - accuracy: 0.2600 - val_loss: 1.8551 - val_accuracy: 0.1833\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 1.7886 - accuracy: 0.2471 - val_loss: 1.8543 - val_accuracy: 0.1867\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.7858 - accuracy: 0.2486 - val_loss: 1.8504 - val_accuracy: 0.1867\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.7819 - accuracy: 0.2471 - val_loss: 1.8443 - val_accuracy: 0.2267\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 264us/step - loss: 1.7794 - accuracy: 0.2643 - val_loss: 1.8468 - val_accuracy: 0.1900\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 1.7762 - accuracy: 0.2486 - val_loss: 1.8411 - val_accuracy: 0.1933\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 1.7744 - accuracy: 0.2514 - val_loss: 1.8486 - val_accuracy: 0.2000\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 295us/step - loss: 1.7716 - accuracy: 0.2700 - val_loss: 1.8472 - val_accuracy: 0.1800\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.7687 - accuracy: 0.2500 - val_loss: 1.8364 - val_accuracy: 0.2033\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 215us/step - loss: 1.7672 - accuracy: 0.2543 - val_loss: 1.8430 - val_accuracy: 0.2200\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 1.7641 - accuracy: 0.2714 - val_loss: 1.8390 - val_accuracy: 0.2167\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.7616 - accuracy: 0.2557 - val_loss: 1.8347 - val_accuracy: 0.2267\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 275us/step - loss: 1.7590 - accuracy: 0.2671 - val_loss: 1.8329 - val_accuracy: 0.2233\n",
      "Epoch 60/1000\n",
      "700/700 [==============================] - 0s 276us/step - loss: 1.7552 - accuracy: 0.2614 - val_loss: 1.8256 - val_accuracy: 0.2500\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 258us/step - loss: 1.7566 - accuracy: 0.2814 - val_loss: 1.8336 - val_accuracy: 0.2400\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 1.7531 - accuracy: 0.2729 - val_loss: 1.8312 - val_accuracy: 0.2267\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 262us/step - loss: 1.7505 - accuracy: 0.2857 - val_loss: 1.8299 - val_accuracy: 0.2000\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.7484 - accuracy: 0.2800 - val_loss: 1.8268 - val_accuracy: 0.2200\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 264us/step - loss: 1.7457 - accuracy: 0.2814 - val_loss: 1.8298 - val_accuracy: 0.2033\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 1.7439 - accuracy: 0.2786 - val_loss: 1.8296 - val_accuracy: 0.2067\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.7419 - accuracy: 0.2700 - val_loss: 1.8299 - val_accuracy: 0.2067\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 1.7405 - accuracy: 0.2729 - val_loss: 1.8238 - val_accuracy: 0.2000\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.7376 - accuracy: 0.2814 - val_loss: 1.8298 - val_accuracy: 0.2167\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 1.7356 - accuracy: 0.2857 - val_loss: 1.8269 - val_accuracy: 0.2433\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.7345 - accuracy: 0.2800 - val_loss: 1.8214 - val_accuracy: 0.2167\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.7328 - accuracy: 0.2857 - val_loss: 1.8226 - val_accuracy: 0.2133\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 1.7298 - accuracy: 0.2800 - val_loss: 1.8252 - val_accuracy: 0.2467\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.7283 - accuracy: 0.2857 - val_loss: 1.8257 - val_accuracy: 0.1967\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.7268 - accuracy: 0.2786 - val_loss: 1.8190 - val_accuracy: 0.2267\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 1.7255 - accuracy: 0.2857 - val_loss: 1.8196 - val_accuracy: 0.2233\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 1.7228 - accuracy: 0.3057 - val_loss: 1.8232 - val_accuracy: 0.2033\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.7212 - accuracy: 0.2857 - val_loss: 1.8187 - val_accuracy: 0.1933\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.7199 - accuracy: 0.2829 - val_loss: 1.8203 - val_accuracy: 0.2433\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.7188 - accuracy: 0.2929 - val_loss: 1.8197 - val_accuracy: 0.2067\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 1.7165 - accuracy: 0.2843 - val_loss: 1.8256 - val_accuracy: 0.2067\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 1.7142 - accuracy: 0.2829 - val_loss: 1.8144 - val_accuracy: 0.2667\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 1.7132 - accuracy: 0.2857 - val_loss: 1.8190 - val_accuracy: 0.2400\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 1.7127 - accuracy: 0.2986 - val_loss: 1.8220 - val_accuracy: 0.2167\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 1.7097 - accuracy: 0.2971 - val_loss: 1.8159 - val_accuracy: 0.2267\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 252us/step - loss: 1.7082 - accuracy: 0.2800 - val_loss: 1.8136 - val_accuracy: 0.2633\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.7051 - accuracy: 0.3100 - val_loss: 1.8191 - val_accuracy: 0.2733\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.7062 - accuracy: 0.3043 - val_loss: 1.8125 - val_accuracy: 0.2433\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.7043 - accuracy: 0.3043 - val_loss: 1.8167 - val_accuracy: 0.2167\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.7027 - accuracy: 0.2843 - val_loss: 1.8151 - val_accuracy: 0.2233\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 318us/step - loss: 1.7017 - accuracy: 0.3086 - val_loss: 1.8185 - val_accuracy: 0.2167\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 1.6987 - accuracy: 0.3129 - val_loss: 1.8215 - val_accuracy: 0.2067\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 290us/step - loss: 1.6980 - accuracy: 0.3071 - val_loss: 1.8173 - val_accuracy: 0.2767\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.6970 - accuracy: 0.3157 - val_loss: 1.8176 - val_accuracy: 0.2100\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 242us/step - loss: 1.6943 - accuracy: 0.2986 - val_loss: 1.8194 - val_accuracy: 0.2833\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 302us/step - loss: 1.6948 - accuracy: 0.3014 - val_loss: 1.8095 - val_accuracy: 0.2233\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 301us/step - loss: 1.6930 - accuracy: 0.3057 - val_loss: 1.8228 - val_accuracy: 0.2300\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 421us/step - loss: 1.6921 - accuracy: 0.3043 - val_loss: 1.8117 - val_accuracy: 0.2200\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 327us/step - loss: 1.6901 - accuracy: 0.3129 - val_loss: 1.8252 - val_accuracy: 0.2233\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.6890 - accuracy: 0.3129 - val_loss: 1.8210 - val_accuracy: 0.2267\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.6878 - accuracy: 0.3143 - val_loss: 1.8190 - val_accuracy: 0.2200\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 1.6877 - accuracy: 0.3014 - val_loss: 1.8219 - val_accuracy: 0.2300\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 1.6843 - accuracy: 0.3000 - val_loss: 1.8102 - val_accuracy: 0.2500\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 1.6842 - accuracy: 0.3200 - val_loss: 1.8122 - val_accuracy: 0.2200\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.6821 - accuracy: 0.3071 - val_loss: 1.8063 - val_accuracy: 0.2067\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 308us/step - loss: 1.6814 - accuracy: 0.3114 - val_loss: 1.8173 - val_accuracy: 0.2200\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 1.6805 - accuracy: 0.3071 - val_loss: 1.8228 - val_accuracy: 0.2367\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.6784 - accuracy: 0.3071 - val_loss: 1.8167 - val_accuracy: 0.2767\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.6782 - accuracy: 0.3143 - val_loss: 1.8178 - val_accuracy: 0.2300\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 267us/step - loss: 1.6775 - accuracy: 0.3171 - val_loss: 1.8147 - val_accuracy: 0.2133\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 1.6775 - accuracy: 0.3043 - val_loss: 1.8173 - val_accuracy: 0.2233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 1.6745 - accuracy: 0.3129 - val_loss: 1.8193 - val_accuracy: 0.2267\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.6737 - accuracy: 0.3100 - val_loss: 1.8196 - val_accuracy: 0.2300\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 327us/step - loss: 1.6724 - accuracy: 0.3014 - val_loss: 1.8221 - val_accuracy: 0.2300\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 1.6711 - accuracy: 0.3071 - val_loss: 1.8128 - val_accuracy: 0.2333\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 1.6703 - accuracy: 0.3157 - val_loss: 1.8255 - val_accuracy: 0.2300\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.6694 - accuracy: 0.3100 - val_loss: 1.8228 - val_accuracy: 0.2333\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 1.6682 - accuracy: 0.3114 - val_loss: 1.8262 - val_accuracy: 0.2333\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 1.6670 - accuracy: 0.3257 - val_loss: 1.8216 - val_accuracy: 0.2200\n",
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 1.6661 - accuracy: 0.3129 - val_loss: 1.8219 - val_accuracy: 0.2200\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 1.6646 - accuracy: 0.3071 - val_loss: 1.8132 - val_accuracy: 0.2233\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.6637 - accuracy: 0.3229 - val_loss: 1.8194 - val_accuracy: 0.2200\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 280us/step - loss: 1.6629 - accuracy: 0.3100 - val_loss: 1.8139 - val_accuracy: 0.2200\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.6619 - accuracy: 0.3143 - val_loss: 1.8187 - val_accuracy: 0.2267\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.6606 - accuracy: 0.3257 - val_loss: 1.8212 - val_accuracy: 0.2333\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.6592 - accuracy: 0.3143 - val_loss: 1.8245 - val_accuracy: 0.2233\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 1.6583 - accuracy: 0.3129 - val_loss: 1.8147 - val_accuracy: 0.2333\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.6565 - accuracy: 0.3300 - val_loss: 1.8280 - val_accuracy: 0.2300\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.6570 - accuracy: 0.3143 - val_loss: 1.8193 - val_accuracy: 0.2200\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 1.6548 - accuracy: 0.3214 - val_loss: 1.8124 - val_accuracy: 0.2533\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.6547 - accuracy: 0.3229 - val_loss: 1.8202 - val_accuracy: 0.2500\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 1.6545 - accuracy: 0.3200 - val_loss: 1.8133 - val_accuracy: 0.2267\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.6524 - accuracy: 0.3143 - val_loss: 1.8317 - val_accuracy: 0.2400\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 346us/step - loss: 1.6514 - accuracy: 0.3214 - val_loss: 1.8226 - val_accuracy: 0.2733\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 274us/step - loss: 1.6512 - accuracy: 0.3314 - val_loss: 1.8233 - val_accuracy: 0.2267\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 159us/step - loss: 1.6493 - accuracy: 0.3186 - val_loss: 1.8168 - val_accuracy: 0.2200\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 1.6483 - accuracy: 0.3214 - val_loss: 1.8191 - val_accuracy: 0.2200\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 1.6488 - accuracy: 0.3257 - val_loss: 1.8199 - val_accuracy: 0.2167\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.6466 - accuracy: 0.3257 - val_loss: 1.8512 - val_accuracy: 0.2433\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 1.6465 - accuracy: 0.3214 - val_loss: 1.8168 - val_accuracy: 0.2200\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.6446 - accuracy: 0.3229 - val_loss: 1.8284 - val_accuracy: 0.2267\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 1.6437 - accuracy: 0.3243 - val_loss: 1.8154 - val_accuracy: 0.2633\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.6437 - accuracy: 0.3329 - val_loss: 1.8292 - val_accuracy: 0.2433\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.6431 - accuracy: 0.3329 - val_loss: 1.8273 - val_accuracy: 0.2300\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 1.6419 - accuracy: 0.3271 - val_loss: 1.8197 - val_accuracy: 0.2200\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 1.6392 - accuracy: 0.3343 - val_loss: 1.8324 - val_accuracy: 0.2233\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 1.6412 - accuracy: 0.3100 - val_loss: 1.8328 - val_accuracy: 0.2333\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.6390 - accuracy: 0.3243 - val_loss: 1.8306 - val_accuracy: 0.2500\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 1.6375 - accuracy: 0.3271 - val_loss: 1.8189 - val_accuracy: 0.2133\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 1.6367 - accuracy: 0.3229 - val_loss: 1.8276 - val_accuracy: 0.2233\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.6364 - accuracy: 0.3257 - val_loss: 1.8245 - val_accuracy: 0.2267\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 266us/step - loss: 1.6350 - accuracy: 0.3214 - val_loss: 1.8290 - val_accuracy: 0.2233\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 286us/step - loss: 1.6340 - accuracy: 0.3400 - val_loss: 1.8270 - val_accuracy: 0.2300\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 284us/step - loss: 1.6319 - accuracy: 0.3457 - val_loss: 1.8343 - val_accuracy: 0.2233\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 337us/step - loss: 1.6316 - accuracy: 0.3243 - val_loss: 1.8183 - val_accuracy: 0.2367\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 1.6326 - accuracy: 0.3329 - val_loss: 1.8309 - val_accuracy: 0.2200\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 1.6308 - accuracy: 0.3300 - val_loss: 1.8241 - val_accuracy: 0.2200\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 1.6308 - accuracy: 0.3343 - val_loss: 1.8329 - val_accuracy: 0.2300\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 372us/step - loss: 1.6285 - accuracy: 0.3257 - val_loss: 1.8336 - val_accuracy: 0.2433\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 1.6278 - accuracy: 0.3300 - val_loss: 1.8304 - val_accuracy: 0.2233\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 255us/step - loss: 1.6271 - accuracy: 0.3257 - val_loss: 1.8406 - val_accuracy: 0.2300\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 1.6265 - accuracy: 0.3271 - val_loss: 1.8350 - val_accuracy: 0.2267\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.6254 - accuracy: 0.3371 - val_loss: 1.8365 - val_accuracy: 0.2300\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.6239 - accuracy: 0.3314 - val_loss: 1.8264 - val_accuracy: 0.2100\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 1.6236 - accuracy: 0.3200 - val_loss: 1.8396 - val_accuracy: 0.2367\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.6230 - accuracy: 0.3286 - val_loss: 1.8344 - val_accuracy: 0.2233\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 204us/step - loss: 1.6221 - accuracy: 0.3314 - val_loss: 1.8389 - val_accuracy: 0.2633\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6208 - accuracy: 0.3386 - val_loss: 1.8444 - val_accuracy: 0.2200\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 296us/step - loss: 1.6198 - accuracy: 0.3386 - val_loss: 1.8525 - val_accuracy: 0.2233\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 281us/step - loss: 1.6191 - accuracy: 0.3371 - val_loss: 1.8369 - val_accuracy: 0.2233\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 279us/step - loss: 1.6170 - accuracy: 0.3271 - val_loss: 1.8517 - val_accuracy: 0.2600\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 300us/step - loss: 1.6164 - accuracy: 0.3386 - val_loss: 1.8397 - val_accuracy: 0.2133\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 1.6182 - accuracy: 0.3386 - val_loss: 1.8392 - val_accuracy: 0.2367\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 1.6167 - accuracy: 0.3300 - val_loss: 1.8420 - val_accuracy: 0.2200\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 1.6166 - accuracy: 0.3357 - val_loss: 1.8406 - val_accuracy: 0.2200\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.6143 - accuracy: 0.3229 - val_loss: 1.8437 - val_accuracy: 0.2600\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 1.6134 - accuracy: 0.3371 - val_loss: 1.8384 - val_accuracy: 0.2167\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.6139 - accuracy: 0.3371 - val_loss: 1.8446 - val_accuracy: 0.2267\n",
      "Epoch 179/1000\n",
      "700/700 [==============================] - 0s 395us/step - loss: 1.6134 - accuracy: 0.3400 - val_loss: 1.8376 - val_accuracy: 0.2233\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.6110 - accuracy: 0.3371 - val_loss: 1.8415 - val_accuracy: 0.2667\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6115 - accuracy: 0.3457 - val_loss: 1.8339 - val_accuracy: 0.2567\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 255us/step - loss: 1.6106 - accuracy: 0.3471 - val_loss: 1.8365 - val_accuracy: 0.2167\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.6115 - accuracy: 0.3300 - val_loss: 1.8411 - val_accuracy: 0.2333\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 1.6093 - accuracy: 0.3443 - val_loss: 1.8453 - val_accuracy: 0.2267\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 1.6076 - accuracy: 0.3386 - val_loss: 1.8641 - val_accuracy: 0.2200\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 1.6086 - accuracy: 0.3443 - val_loss: 1.8449 - val_accuracy: 0.2233\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 1.6065 - accuracy: 0.3543 - val_loss: 1.8442 - val_accuracy: 0.2167\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 1.6075 - accuracy: 0.3386 - val_loss: 1.8412 - val_accuracy: 0.2133\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 274us/step - loss: 1.6045 - accuracy: 0.3529 - val_loss: 1.8517 - val_accuracy: 0.2233\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 1.6065 - accuracy: 0.3314 - val_loss: 1.8401 - val_accuracy: 0.2300\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 239us/step - loss: 1.6042 - accuracy: 0.3529 - val_loss: 1.8564 - val_accuracy: 0.2233\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 261us/step - loss: 1.6044 - accuracy: 0.3500 - val_loss: 1.8503 - val_accuracy: 0.2200\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 280us/step - loss: 1.6029 - accuracy: 0.3357 - val_loss: 1.8539 - val_accuracy: 0.2267\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.6025 - accuracy: 0.3414 - val_loss: 1.8470 - val_accuracy: 0.2267\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 181us/step - loss: 1.6019 - accuracy: 0.3457 - val_loss: 1.8453 - val_accuracy: 0.2467\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6016 - accuracy: 0.3514 - val_loss: 1.8472 - val_accuracy: 0.2167\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 1.6002 - accuracy: 0.3443 - val_loss: 1.8488 - val_accuracy: 0.2300\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.6005 - accuracy: 0.3386 - val_loss: 1.8591 - val_accuracy: 0.2200\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.6003 - accuracy: 0.3429 - val_loss: 1.8558 - val_accuracy: 0.2200\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.5975 - accuracy: 0.3457 - val_loss: 1.8604 - val_accuracy: 0.2633\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 1.5986 - accuracy: 0.3457 - val_loss: 1.8469 - val_accuracy: 0.2167\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.5979 - accuracy: 0.3414 - val_loss: 1.8478 - val_accuracy: 0.2100\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.5965 - accuracy: 0.3343 - val_loss: 1.8562 - val_accuracy: 0.2267\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 255us/step - loss: 1.5953 - accuracy: 0.3557 - val_loss: 1.8461 - val_accuracy: 0.2067\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.5953 - accuracy: 0.3429 - val_loss: 1.8508 - val_accuracy: 0.2200\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 239us/step - loss: 1.5946 - accuracy: 0.3500 - val_loss: 1.8463 - val_accuracy: 0.2133\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5947 - accuracy: 0.3543 - val_loss: 1.8537 - val_accuracy: 0.2233\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5920 - accuracy: 0.3414 - val_loss: 1.8557 - val_accuracy: 0.2233\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 271us/step - loss: 1.5919 - accuracy: 0.3514 - val_loss: 1.8521 - val_accuracy: 0.2300\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 271us/step - loss: 1.5915 - accuracy: 0.3443 - val_loss: 1.8523 - val_accuracy: 0.2267\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 377us/step - loss: 1.5903 - accuracy: 0.3371 - val_loss: 1.8456 - val_accuracy: 0.2567\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.5913 - accuracy: 0.3471 - val_loss: 1.8593 - val_accuracy: 0.2200\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 1.5894 - accuracy: 0.3500 - val_loss: 1.8519 - val_accuracy: 0.2233\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 249us/step - loss: 1.5905 - accuracy: 0.3457 - val_loss: 1.8541 - val_accuracy: 0.2267\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.5886 - accuracy: 0.3514 - val_loss: 1.8602 - val_accuracy: 0.2667\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5895 - accuracy: 0.3486 - val_loss: 1.8624 - val_accuracy: 0.2267\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 1.5881 - accuracy: 0.3471 - val_loss: 1.8638 - val_accuracy: 0.2300\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.5876 - accuracy: 0.3486 - val_loss: 1.8600 - val_accuracy: 0.2300\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 1.5865 - accuracy: 0.3500 - val_loss: 1.8659 - val_accuracy: 0.2267\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 1.5855 - accuracy: 0.3514 - val_loss: 1.8581 - val_accuracy: 0.2267\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.5855 - accuracy: 0.3471 - val_loss: 1.8621 - val_accuracy: 0.2267\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 228us/step - loss: 1.5845 - accuracy: 0.3514 - val_loss: 1.8751 - val_accuracy: 0.2500\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 1.5844 - accuracy: 0.3443 - val_loss: 1.8615 - val_accuracy: 0.2600\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.5845 - accuracy: 0.3529 - val_loss: 1.8766 - val_accuracy: 0.2467\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 311us/step - loss: 1.5833 - accuracy: 0.3457 - val_loss: 1.8572 - val_accuracy: 0.2167\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5835 - accuracy: 0.3486 - val_loss: 1.8686 - val_accuracy: 0.2233\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 1.5825 - accuracy: 0.3486 - val_loss: 1.8611 - val_accuracy: 0.2133\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 1.5825 - accuracy: 0.3443 - val_loss: 1.8693 - val_accuracy: 0.2267\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 1.5801 - accuracy: 0.3471 - val_loss: 1.8688 - val_accuracy: 0.2233\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 1.5818 - accuracy: 0.3471 - val_loss: 1.8635 - val_accuracy: 0.2133\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.5797 - accuracy: 0.3529 - val_loss: 1.8605 - val_accuracy: 0.2200\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 181us/step - loss: 1.5809 - accuracy: 0.3514 - val_loss: 1.8730 - val_accuracy: 0.2133\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.5796 - accuracy: 0.3486 - val_loss: 1.8781 - val_accuracy: 0.2200\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 1.5791 - accuracy: 0.3457 - val_loss: 1.8666 - val_accuracy: 0.2133\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.5777 - accuracy: 0.3571 - val_loss: 1.8693 - val_accuracy: 0.2100\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 1.5778 - accuracy: 0.3443 - val_loss: 1.8664 - val_accuracy: 0.2133\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 242us/step - loss: 1.5770 - accuracy: 0.3429 - val_loss: 1.8718 - val_accuracy: 0.2300\n",
      "Epoch 238/1000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.5774 - accuracy: 0.3471 - val_loss: 1.8613 - val_accuracy: 0.2200\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.5770 - accuracy: 0.3571 - val_loss: 1.8682 - val_accuracy: 0.2267\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 1.5749 - accuracy: 0.3571 - val_loss: 1.8719 - val_accuracy: 0.2500\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 232us/step - loss: 1.5749 - accuracy: 0.3571 - val_loss: 1.8738 - val_accuracy: 0.2433\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5743 - accuracy: 0.3514 - val_loss: 1.8733 - val_accuracy: 0.2100\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.5743 - accuracy: 0.3629 - val_loss: 1.8806 - val_accuracy: 0.2200\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 232us/step - loss: 1.5713 - accuracy: 0.3557 - val_loss: 1.8724 - val_accuracy: 0.2200\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 1.5715 - accuracy: 0.3586 - val_loss: 1.8838 - val_accuracy: 0.2233\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 225us/step - loss: 1.5712 - accuracy: 0.3543 - val_loss: 1.8710 - val_accuracy: 0.2533\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.5722 - accuracy: 0.3557 - val_loss: 1.8631 - val_accuracy: 0.2167\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.5716 - accuracy: 0.3557 - val_loss: 1.8700 - val_accuracy: 0.2233\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 239us/step - loss: 1.5712 - accuracy: 0.3471 - val_loss: 1.8840 - val_accuracy: 0.2233\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.5680 - accuracy: 0.3657 - val_loss: 1.8981 - val_accuracy: 0.2167\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.5704 - accuracy: 0.3486 - val_loss: 1.8793 - val_accuracy: 0.2400\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.5682 - accuracy: 0.3643 - val_loss: 1.8744 - val_accuracy: 0.2200\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5689 - accuracy: 0.3586 - val_loss: 1.8820 - val_accuracy: 0.2133\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.5677 - accuracy: 0.3571 - val_loss: 1.8835 - val_accuracy: 0.2267\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 1.5681 - accuracy: 0.3457 - val_loss: 1.8713 - val_accuracy: 0.2267\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 255us/step - loss: 1.5657 - accuracy: 0.3571 - val_loss: 1.8761 - val_accuracy: 0.2533\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 305us/step - loss: 1.5667 - accuracy: 0.3514 - val_loss: 1.8912 - val_accuracy: 0.2467\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 239us/step - loss: 1.5649 - accuracy: 0.3614 - val_loss: 1.8946 - val_accuracy: 0.2567\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.5648 - accuracy: 0.3643 - val_loss: 1.8911 - val_accuracy: 0.2167\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 293us/step - loss: 1.5657 - accuracy: 0.3600 - val_loss: 1.8989 - val_accuracy: 0.2200\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 1.5637 - accuracy: 0.3571 - val_loss: 1.8751 - val_accuracy: 0.2167\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.5638 - accuracy: 0.3614 - val_loss: 1.8836 - val_accuracy: 0.2100\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 258us/step - loss: 1.5631 - accuracy: 0.3629 - val_loss: 1.8858 - val_accuracy: 0.2100\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 313us/step - loss: 1.5640 - accuracy: 0.3571 - val_loss: 1.8812 - val_accuracy: 0.2133\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 225us/step - loss: 1.5638 - accuracy: 0.3686 - val_loss: 1.8902 - val_accuracy: 0.2200\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 291us/step - loss: 1.5614 - accuracy: 0.3614 - val_loss: 1.8968 - val_accuracy: 0.2500\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 330us/step - loss: 1.5612 - accuracy: 0.3629 - val_loss: 1.8918 - val_accuracy: 0.2300\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 242us/step - loss: 1.5613 - accuracy: 0.3614 - val_loss: 1.8757 - val_accuracy: 0.2100\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.5601 - accuracy: 0.3643 - val_loss: 1.8854 - val_accuracy: 0.2133\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 287us/step - loss: 1.5594 - accuracy: 0.3671 - val_loss: 1.8674 - val_accuracy: 0.2333\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 258us/step - loss: 1.5610 - accuracy: 0.3657 - val_loss: 1.8914 - val_accuracy: 0.2333\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 255us/step - loss: 1.5595 - accuracy: 0.3600 - val_loss: 1.9030 - val_accuracy: 0.2267\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 262us/step - loss: 1.5591 - accuracy: 0.3571 - val_loss: 1.8964 - val_accuracy: 0.2200\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.5589 - accuracy: 0.3457 - val_loss: 1.8841 - val_accuracy: 0.2233\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.5589 - accuracy: 0.3629 - val_loss: 1.8914 - val_accuracy: 0.2200\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 1.5579 - accuracy: 0.3529 - val_loss: 1.8967 - val_accuracy: 0.2533\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 210us/step - loss: 1.5581 - accuracy: 0.3714 - val_loss: 1.8909 - val_accuracy: 0.2167\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.5578 - accuracy: 0.3600 - val_loss: 1.9032 - val_accuracy: 0.2300\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5559 - accuracy: 0.3571 - val_loss: 1.8859 - val_accuracy: 0.2167\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 1.5559 - accuracy: 0.3700 - val_loss: 1.8876 - val_accuracy: 0.2167\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 324us/step - loss: 1.5541 - accuracy: 0.3586 - val_loss: 1.8906 - val_accuracy: 0.2333\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.5553 - accuracy: 0.3671 - val_loss: 1.8840 - val_accuracy: 0.2133\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5543 - accuracy: 0.3557 - val_loss: 1.8927 - val_accuracy: 0.2167\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 1.5542 - accuracy: 0.3614 - val_loss: 1.8936 - val_accuracy: 0.2567\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.5535 - accuracy: 0.3557 - val_loss: 1.8887 - val_accuracy: 0.2200\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.5536 - accuracy: 0.3586 - val_loss: 1.8989 - val_accuracy: 0.2233\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 1.5527 - accuracy: 0.3686 - val_loss: 1.9019 - val_accuracy: 0.2133\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 1.5525 - accuracy: 0.3600 - val_loss: 1.8930 - val_accuracy: 0.2133\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 225us/step - loss: 1.5519 - accuracy: 0.3600 - val_loss: 1.9014 - val_accuracy: 0.2167\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 276us/step - loss: 1.5514 - accuracy: 0.3657 - val_loss: 1.9032 - val_accuracy: 0.2200\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 1.5513 - accuracy: 0.3586 - val_loss: 1.9037 - val_accuracy: 0.2167\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 1.5509 - accuracy: 0.3543 - val_loss: 1.8995 - val_accuracy: 0.2433\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5507 - accuracy: 0.3543 - val_loss: 1.9011 - val_accuracy: 0.2300\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5497 - accuracy: 0.3543 - val_loss: 1.9002 - val_accuracy: 0.2567\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 265us/step - loss: 1.5499 - accuracy: 0.3657 - val_loss: 1.9120 - val_accuracy: 0.2200\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 284us/step - loss: 1.5495 - accuracy: 0.3571 - val_loss: 1.9104 - val_accuracy: 0.2133\n",
      "Epoch 297/1000\n",
      "700/700 [==============================] - 0s 285us/step - loss: 1.5479 - accuracy: 0.3571 - val_loss: 1.9128 - val_accuracy: 0.2167\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s 301us/step - loss: 1.5477 - accuracy: 0.3486 - val_loss: 1.8958 - val_accuracy: 0.2267\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 202us/step - loss: 1.5485 - accuracy: 0.3686 - val_loss: 1.9145 - val_accuracy: 0.2267\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 1.5472 - accuracy: 0.3629 - val_loss: 1.9031 - val_accuracy: 0.2300\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.5469 - accuracy: 0.3629 - val_loss: 1.8934 - val_accuracy: 0.2200\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.5479 - accuracy: 0.3657 - val_loss: 1.9081 - val_accuracy: 0.2167\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.5464 - accuracy: 0.3529 - val_loss: 1.9016 - val_accuracy: 0.2333\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 232us/step - loss: 1.5452 - accuracy: 0.3671 - val_loss: 1.9066 - val_accuracy: 0.2200\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 1.5432 - accuracy: 0.3643 - val_loss: 1.9140 - val_accuracy: 0.2267\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.5458 - accuracy: 0.3600 - val_loss: 1.9100 - val_accuracy: 0.2233\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 249us/step - loss: 1.5436 - accuracy: 0.3671 - val_loss: 1.9064 - val_accuracy: 0.2267\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5453 - accuracy: 0.3600 - val_loss: 1.9129 - val_accuracy: 0.2333\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 1.5435 - accuracy: 0.3643 - val_loss: 1.9120 - val_accuracy: 0.2367\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 272us/step - loss: 1.5448 - accuracy: 0.3671 - val_loss: 1.9110 - val_accuracy: 0.2167\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 294us/step - loss: 1.5426 - accuracy: 0.3586 - val_loss: 1.9058 - val_accuracy: 0.2300\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 270us/step - loss: 1.5423 - accuracy: 0.3729 - val_loss: 1.9273 - val_accuracy: 0.2367\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 1.5387 - accuracy: 0.3657 - val_loss: 1.9056 - val_accuracy: 0.2633\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 280us/step - loss: 1.5433 - accuracy: 0.3686 - val_loss: 1.9131 - val_accuracy: 0.2300\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 350us/step - loss: 1.5406 - accuracy: 0.3657 - val_loss: 1.9118 - val_accuracy: 0.2233\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 291us/step - loss: 1.5404 - accuracy: 0.3614 - val_loss: 1.9141 - val_accuracy: 0.2233\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 301us/step - loss: 1.5412 - accuracy: 0.3614 - val_loss: 1.9213 - val_accuracy: 0.2333\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 1.5408 - accuracy: 0.3614 - val_loss: 1.9096 - val_accuracy: 0.2300\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 289us/step - loss: 1.5390 - accuracy: 0.3614 - val_loss: 1.9092 - val_accuracy: 0.2300\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 274us/step - loss: 1.5392 - accuracy: 0.3629 - val_loss: 1.9278 - val_accuracy: 0.2233\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.5392 - accuracy: 0.3686 - val_loss: 1.9258 - val_accuracy: 0.2300\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5375 - accuracy: 0.3671 - val_loss: 1.9181 - val_accuracy: 0.2533\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5383 - accuracy: 0.3714 - val_loss: 1.9197 - val_accuracy: 0.2300\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 1.5373 - accuracy: 0.3657 - val_loss: 1.9227 - val_accuracy: 0.2200\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 1.5387 - accuracy: 0.3600 - val_loss: 1.9178 - val_accuracy: 0.2133\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 1.5365 - accuracy: 0.3614 - val_loss: 1.9227 - val_accuracy: 0.2200\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 1.5359 - accuracy: 0.3743 - val_loss: 1.9378 - val_accuracy: 0.2333\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 1.5366 - accuracy: 0.3657 - val_loss: 1.9307 - val_accuracy: 0.2233\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.5354 - accuracy: 0.3714 - val_loss: 1.9147 - val_accuracy: 0.2300\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 1.5351 - accuracy: 0.3600 - val_loss: 1.9222 - val_accuracy: 0.2333\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 202us/step - loss: 1.5338 - accuracy: 0.3714 - val_loss: 1.9155 - val_accuracy: 0.2200\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 210us/step - loss: 1.5346 - accuracy: 0.3571 - val_loss: 1.9340 - val_accuracy: 0.2500\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 1.5358 - accuracy: 0.3671 - val_loss: 1.9234 - val_accuracy: 0.2233\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 1.5349 - accuracy: 0.3629 - val_loss: 1.9289 - val_accuracy: 0.2233\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 1.5327 - accuracy: 0.3757 - val_loss: 1.9246 - val_accuracy: 0.2567\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.5335 - accuracy: 0.3786 - val_loss: 1.9184 - val_accuracy: 0.2300\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 1.5330 - accuracy: 0.3757 - val_loss: 1.9324 - val_accuracy: 0.2300\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 1.5320 - accuracy: 0.3743 - val_loss: 1.9238 - val_accuracy: 0.2133\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 1.5314 - accuracy: 0.3700 - val_loss: 1.9157 - val_accuracy: 0.2167\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 1.5328 - accuracy: 0.3729 - val_loss: 1.9403 - val_accuracy: 0.2267\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 1.5317 - accuracy: 0.3757 - val_loss: 1.9258 - val_accuracy: 0.2267\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.5313 - accuracy: 0.3600 - val_loss: 1.9441 - val_accuracy: 0.2167\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 1.5310 - accuracy: 0.3686 - val_loss: 1.9333 - val_accuracy: 0.2267\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 1.5308 - accuracy: 0.3671 - val_loss: 1.9431 - val_accuracy: 0.2300\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.5291 - accuracy: 0.3686 - val_loss: 1.9443 - val_accuracy: 0.2567\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 1.5301 - accuracy: 0.3700 - val_loss: 1.9314 - val_accuracy: 0.2267\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 1.5277 - accuracy: 0.3800 - val_loss: 1.9199 - val_accuracy: 0.2200\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 1.5284 - accuracy: 0.3643 - val_loss: 1.9294 - val_accuracy: 0.2167\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 265us/step - loss: 1.5281 - accuracy: 0.3700 - val_loss: 1.9273 - val_accuracy: 0.2133\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 1.5282 - accuracy: 0.3657 - val_loss: 1.9311 - val_accuracy: 0.2300\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 1.5264 - accuracy: 0.3757 - val_loss: 1.9309 - val_accuracy: 0.2333\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 1.5283 - accuracy: 0.3729 - val_loss: 1.9282 - val_accuracy: 0.2300\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 1.5256 - accuracy: 0.3657 - val_loss: 1.9422 - val_accuracy: 0.2300\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.5279 - accuracy: 0.3700 - val_loss: 1.9350 - val_accuracy: 0.2167\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 1.5261 - accuracy: 0.3600 - val_loss: 1.9553 - val_accuracy: 0.2267\n",
      "Epoch 356/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.5260 - accuracy: 0.3700 - val_loss: 1.9442 - val_accuracy: 0.2433\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.5259 - accuracy: 0.3743 - val_loss: 1.9355 - val_accuracy: 0.2267\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.5251 - accuracy: 0.3729 - val_loss: 1.9494 - val_accuracy: 0.2233\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.5251 - accuracy: 0.3729 - val_loss: 1.9450 - val_accuracy: 0.2133\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.5232 - accuracy: 0.3743 - val_loss: 1.9454 - val_accuracy: 0.2233\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 258us/step - loss: 1.5232 - accuracy: 0.3686 - val_loss: 1.9485 - val_accuracy: 0.2300\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5240 - accuracy: 0.3643 - val_loss: 1.9508 - val_accuracy: 0.2267\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 1.5215 - accuracy: 0.3757 - val_loss: 1.9527 - val_accuracy: 0.2333\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.5230 - accuracy: 0.3643 - val_loss: 1.9381 - val_accuracy: 0.2300\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.5224 - accuracy: 0.3771 - val_loss: 1.9524 - val_accuracy: 0.2267\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 322us/step - loss: 1.5222 - accuracy: 0.3686 - val_loss: 1.9406 - val_accuracy: 0.2133\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 1.5221 - accuracy: 0.3757 - val_loss: 1.9567 - val_accuracy: 0.2300\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 1.5206 - accuracy: 0.3786 - val_loss: 1.9551 - val_accuracy: 0.2367\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5207 - accuracy: 0.3629 - val_loss: 1.9321 - val_accuracy: 0.2367\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.5200 - accuracy: 0.3757 - val_loss: 1.9534 - val_accuracy: 0.2400\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s 293us/step - loss: 1.5209 - accuracy: 0.3671 - val_loss: 1.9508 - val_accuracy: 0.2233\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 1.5195 - accuracy: 0.3729 - val_loss: 1.9590 - val_accuracy: 0.2333\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.5205 - accuracy: 0.3757 - val_loss: 1.9453 - val_accuracy: 0.2133\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 320us/step - loss: 1.5197 - accuracy: 0.3686 - val_loss: 1.9514 - val_accuracy: 0.2267\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.5181 - accuracy: 0.3843 - val_loss: 1.9386 - val_accuracy: 0.2267\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 1.5182 - accuracy: 0.3800 - val_loss: 1.9487 - val_accuracy: 0.2167\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 298us/step - loss: 1.5170 - accuracy: 0.3743 - val_loss: 1.9760 - val_accuracy: 0.2267\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 274us/step - loss: 1.5182 - accuracy: 0.3743 - val_loss: 1.9761 - val_accuracy: 0.2367\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.5188 - accuracy: 0.3700 - val_loss: 1.9516 - val_accuracy: 0.2367\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.5166 - accuracy: 0.3671 - val_loss: 1.9602 - val_accuracy: 0.2567\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.5180 - accuracy: 0.3786 - val_loss: 1.9711 - val_accuracy: 0.2167\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 181us/step - loss: 1.5161 - accuracy: 0.3743 - val_loss: 1.9585 - val_accuracy: 0.2267\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.5155 - accuracy: 0.3700 - val_loss: 1.9714 - val_accuracy: 0.2433\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 361us/step - loss: 1.5164 - accuracy: 0.3771 - val_loss: 1.9509 - val_accuracy: 0.2233\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 261us/step - loss: 1.5163 - accuracy: 0.3743 - val_loss: 1.9579 - val_accuracy: 0.2267\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 377us/step - loss: 1.5156 - accuracy: 0.3714 - val_loss: 1.9502 - val_accuracy: 0.2333\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 227us/step - loss: 1.5153 - accuracy: 0.3743 - val_loss: 1.9578 - val_accuracy: 0.2300\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.5143 - accuracy: 0.3714 - val_loss: 1.9668 - val_accuracy: 0.2467\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.5158 - accuracy: 0.3800 - val_loss: 1.9490 - val_accuracy: 0.2267\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.5125 - accuracy: 0.3671 - val_loss: 1.9572 - val_accuracy: 0.2400\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 1.5132 - accuracy: 0.3757 - val_loss: 1.9539 - val_accuracy: 0.2367\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 1.5137 - accuracy: 0.3714 - val_loss: 1.9599 - val_accuracy: 0.2233\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 1.5137 - accuracy: 0.3757 - val_loss: 1.9730 - val_accuracy: 0.2233\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 1.5136 - accuracy: 0.3757 - val_loss: 1.9565 - val_accuracy: 0.2267\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5132 - accuracy: 0.3771 - val_loss: 1.9565 - val_accuracy: 0.2167\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.5124 - accuracy: 0.3771 - val_loss: 1.9619 - val_accuracy: 0.2167\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 1.5111 - accuracy: 0.3857 - val_loss: 1.9755 - val_accuracy: 0.2367\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5124 - accuracy: 0.3643 - val_loss: 1.9588 - val_accuracy: 0.2200\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 317us/step - loss: 1.5107 - accuracy: 0.3743 - val_loss: 1.9904 - val_accuracy: 0.2333\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 282us/step - loss: 1.5113 - accuracy: 0.3643 - val_loss: 1.9599 - val_accuracy: 0.2167\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 269us/step - loss: 1.5109 - accuracy: 0.3657 - val_loss: 1.9595 - val_accuracy: 0.2267\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 1.5086 - accuracy: 0.3771 - val_loss: 1.9650 - val_accuracy: 0.2233\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 350us/step - loss: 1.5068 - accuracy: 0.3843 - val_loss: 1.9968 - val_accuracy: 0.2200\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.5085 - accuracy: 0.3743 - val_loss: 1.9680 - val_accuracy: 0.2333\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.5074 - accuracy: 0.3800 - val_loss: 1.9833 - val_accuracy: 0.2300\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.5085 - accuracy: 0.3771 - val_loss: 1.9756 - val_accuracy: 0.2200\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.5080 - accuracy: 0.3714 - val_loss: 1.9815 - val_accuracy: 0.2267\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 1.5077 - accuracy: 0.3757 - val_loss: 1.9711 - val_accuracy: 0.2267\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.5040 - accuracy: 0.3700 - val_loss: 1.9807 - val_accuracy: 0.2367\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 1.5058 - accuracy: 0.3771 - val_loss: 1.9611 - val_accuracy: 0.2267\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.5056 - accuracy: 0.3714 - val_loss: 1.9846 - val_accuracy: 0.2300\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.5048 - accuracy: 0.3843 - val_loss: 1.9728 - val_accuracy: 0.2233\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.5033 - accuracy: 0.3771 - val_loss: 1.9781 - val_accuracy: 0.2333\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 1.5043 - accuracy: 0.3786 - val_loss: 1.9881 - val_accuracy: 0.2333\n",
      "Epoch 415/1000\n",
      "700/700 [==============================] - 0s 255us/step - loss: 1.5015 - accuracy: 0.3786 - val_loss: 1.9798 - val_accuracy: 0.2333\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.5031 - accuracy: 0.3843 - val_loss: 1.9929 - val_accuracy: 0.2267\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 1.5032 - accuracy: 0.3786 - val_loss: 1.9828 - val_accuracy: 0.2200\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.5016 - accuracy: 0.3871 - val_loss: 1.9756 - val_accuracy: 0.2333\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 1.5019 - accuracy: 0.3786 - val_loss: 1.9663 - val_accuracy: 0.2200\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 202us/step - loss: 1.5015 - accuracy: 0.3800 - val_loss: 1.9912 - val_accuracy: 0.2300\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 345us/step - loss: 1.5011 - accuracy: 0.3829 - val_loss: 1.9693 - val_accuracy: 0.2433\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 258us/step - loss: 1.5004 - accuracy: 0.3743 - val_loss: 1.9759 - val_accuracy: 0.2433\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.5003 - accuracy: 0.3814 - val_loss: 1.9815 - val_accuracy: 0.2333\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 1.5001 - accuracy: 0.3757 - val_loss: 1.9681 - val_accuracy: 0.2200\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.4991 - accuracy: 0.3886 - val_loss: 1.9619 - val_accuracy: 0.2400\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 1.4984 - accuracy: 0.3914 - val_loss: 1.9803 - val_accuracy: 0.2167\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 274us/step - loss: 1.4983 - accuracy: 0.3814 - val_loss: 1.9858 - val_accuracy: 0.2533\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 1.4984 - accuracy: 0.3843 - val_loss: 2.0113 - val_accuracy: 0.2300\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4982 - accuracy: 0.3771 - val_loss: 1.9701 - val_accuracy: 0.2300\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.4977 - accuracy: 0.3814 - val_loss: 1.9836 - val_accuracy: 0.2467\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 1.4990 - accuracy: 0.3786 - val_loss: 1.9920 - val_accuracy: 0.2333\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4974 - accuracy: 0.3843 - val_loss: 1.9780 - val_accuracy: 0.2233\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.4967 - accuracy: 0.3814 - val_loss: 1.9880 - val_accuracy: 0.2367\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 1.4976 - accuracy: 0.3743 - val_loss: 1.9917 - val_accuracy: 0.2233\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.4957 - accuracy: 0.3900 - val_loss: 1.9837 - val_accuracy: 0.2267\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.4975 - accuracy: 0.3843 - val_loss: 1.9691 - val_accuracy: 0.2233\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 1.4957 - accuracy: 0.3943 - val_loss: 1.9995 - val_accuracy: 0.2200\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 1.4948 - accuracy: 0.3857 - val_loss: 1.9635 - val_accuracy: 0.2300\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 1.4946 - accuracy: 0.3771 - val_loss: 1.9794 - val_accuracy: 0.2233\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 313us/step - loss: 1.4960 - accuracy: 0.3800 - val_loss: 1.9815 - val_accuracy: 0.2300\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4951 - accuracy: 0.3886 - val_loss: 1.9841 - val_accuracy: 0.2300\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 318us/step - loss: 1.4944 - accuracy: 0.3829 - val_loss: 1.9982 - val_accuracy: 0.2233\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.4937 - accuracy: 0.3857 - val_loss: 1.9936 - val_accuracy: 0.2400\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 1.4946 - accuracy: 0.3829 - val_loss: 1.9965 - val_accuracy: 0.2233\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 265us/step - loss: 1.4942 - accuracy: 0.3829 - val_loss: 2.0001 - val_accuracy: 0.2300\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 1.4931 - accuracy: 0.3886 - val_loss: 2.0088 - val_accuracy: 0.2267\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4926 - accuracy: 0.3800 - val_loss: 2.0223 - val_accuracy: 0.2300\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 282us/step - loss: 1.4927 - accuracy: 0.3843 - val_loss: 1.9971 - val_accuracy: 0.2267\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.4918 - accuracy: 0.3886 - val_loss: 2.0059 - val_accuracy: 0.2333\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.4929 - accuracy: 0.3843 - val_loss: 1.9975 - val_accuracy: 0.2233\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 1.4919 - accuracy: 0.3843 - val_loss: 2.0043 - val_accuracy: 0.2233\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 1.4908 - accuracy: 0.3857 - val_loss: 1.9997 - val_accuracy: 0.2300\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 1.4910 - accuracy: 0.3871 - val_loss: 1.9943 - val_accuracy: 0.2333\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 275us/step - loss: 1.4908 - accuracy: 0.3871 - val_loss: 2.0016 - val_accuracy: 0.2333\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s 298us/step - loss: 1.4907 - accuracy: 0.3843 - val_loss: 1.9913 - val_accuracy: 0.2233\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 1.4898 - accuracy: 0.3786 - val_loss: 1.9959 - val_accuracy: 0.2467\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 1.4899 - accuracy: 0.3871 - val_loss: 2.0019 - val_accuracy: 0.2333\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 1.4902 - accuracy: 0.3857 - val_loss: 1.9970 - val_accuracy: 0.2267\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4900 - accuracy: 0.39 - 0s 227us/step - loss: 1.4881 - accuracy: 0.3943 - val_loss: 1.9948 - val_accuracy: 0.2433\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.4900 - accuracy: 0.3886 - val_loss: 2.0062 - val_accuracy: 0.2300\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.4883 - accuracy: 0.3957 - val_loss: 2.0089 - val_accuracy: 0.2300\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 1.4883 - accuracy: 0.3900 - val_loss: 1.9980 - val_accuracy: 0.2267\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 1.4872 - accuracy: 0.3857 - val_loss: 2.0059 - val_accuracy: 0.2467\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4871 - accuracy: 0.3871 - val_loss: 1.9923 - val_accuracy: 0.2333\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 1.4877 - accuracy: 0.3900 - val_loss: 2.0023 - val_accuracy: 0.2233\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 1.4871 - accuracy: 0.3757 - val_loss: 2.0065 - val_accuracy: 0.2267\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 1.4873 - accuracy: 0.3871 - val_loss: 2.0133 - val_accuracy: 0.2300\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 1.4865 - accuracy: 0.3829 - val_loss: 1.9941 - val_accuracy: 0.2267\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 1.4859 - accuracy: 0.3871 - val_loss: 2.0429 - val_accuracy: 0.2333\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 1.4871 - accuracy: 0.3871 - val_loss: 2.0173 - val_accuracy: 0.2233\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.4859 - accuracy: 0.3957 - val_loss: 2.0124 - val_accuracy: 0.2267\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 436us/step - loss: 1.4845 - accuracy: 0.3971 - val_loss: 2.0157 - val_accuracy: 0.2367\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s 242us/step - loss: 1.4850 - accuracy: 0.3914 - val_loss: 2.0205 - val_accuracy: 0.2367\n",
      "Epoch 474/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 1.4838 - accuracy: 0.3900 - val_loss: 2.0030 - val_accuracy: 0.2267\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.4842 - accuracy: 0.3900 - val_loss: 2.0116 - val_accuracy: 0.2233\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 1.4835 - accuracy: 0.3900 - val_loss: 2.0127 - val_accuracy: 0.2267\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 1.4839 - accuracy: 0.3900 - val_loss: 2.0173 - val_accuracy: 0.2267\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.4838 - accuracy: 0.3929 - val_loss: 2.0124 - val_accuracy: 0.2333\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4833 - accuracy: 0.3900 - val_loss: 2.0080 - val_accuracy: 0.2300\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.4824 - accuracy: 0.3957 - val_loss: 2.0183 - val_accuracy: 0.2367\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 1.4821 - accuracy: 0.3871 - val_loss: 2.0288 - val_accuracy: 0.2400\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 1.4810 - accuracy: 0.3986 - val_loss: 2.0248 - val_accuracy: 0.2300\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 1.4821 - accuracy: 0.4000 - val_loss: 2.0233 - val_accuracy: 0.2367\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.4815 - accuracy: 0.3986 - val_loss: 2.0255 - val_accuracy: 0.2400\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 1.4811 - accuracy: 0.4029 - val_loss: 2.0243 - val_accuracy: 0.2300\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4882 - accuracy: 0.39 - 0s 228us/step - loss: 1.4808 - accuracy: 0.3857 - val_loss: 2.0156 - val_accuracy: 0.2467\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.4811 - accuracy: 0.3957 - val_loss: 2.0159 - val_accuracy: 0.2500\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 1.4808 - accuracy: 0.3914 - val_loss: 2.0247 - val_accuracy: 0.2500\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.4804 - accuracy: 0.3886 - val_loss: 2.0107 - val_accuracy: 0.2267\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.4809 - accuracy: 0.3900 - val_loss: 2.0066 - val_accuracy: 0.2333\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.4808 - accuracy: 0.3871 - val_loss: 2.0321 - val_accuracy: 0.2300\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s 292us/step - loss: 1.4800 - accuracy: 0.3914 - val_loss: 2.0072 - val_accuracy: 0.2267\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4799 - accuracy: 0.4014 - val_loss: 2.0164 - val_accuracy: 0.2333\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4802 - accuracy: 0.3900 - val_loss: 2.0155 - val_accuracy: 0.2233\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4792 - accuracy: 0.4029 - val_loss: 2.0383 - val_accuracy: 0.2333\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 256us/step - loss: 1.4786 - accuracy: 0.3857 - val_loss: 2.0199 - val_accuracy: 0.2433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 1.4773 - accuracy: 0.3929 - val_loss: 2.0210 - val_accuracy: 0.2467\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.4763 - accuracy: 0.3886 - val_loss: 2.0652 - val_accuracy: 0.2367\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 1.4775 - accuracy: 0.4014 - val_loss: 2.0415 - val_accuracy: 0.2367\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.4780 - accuracy: 0.3929 - val_loss: 2.0389 - val_accuracy: 0.2367\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.4782 - accuracy: 0.4000 - val_loss: 2.0378 - val_accuracy: 0.2300\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 291us/step - loss: 1.4760 - accuracy: 0.3943 - val_loss: 2.0391 - val_accuracy: 0.2267\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 1.4766 - accuracy: 0.3957 - val_loss: 2.0315 - val_accuracy: 0.2267\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 314us/step - loss: 1.4757 - accuracy: 0.3971 - val_loss: 2.0373 - val_accuracy: 0.2267\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 461us/step - loss: 1.4754 - accuracy: 0.3957 - val_loss: 2.0319 - val_accuracy: 0.2400\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.4754 - accuracy: 0.3986 - val_loss: 2.0256 - val_accuracy: 0.2300\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.4769 - accuracy: 0.3986 - val_loss: 2.0355 - val_accuracy: 0.2233\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 245us/step - loss: 1.4750 - accuracy: 0.3900 - val_loss: 2.0376 - val_accuracy: 0.2267\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 252us/step - loss: 1.4744 - accuracy: 0.3943 - val_loss: 2.0544 - val_accuracy: 0.2333\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4745 - accuracy: 0.3914 - val_loss: 2.0370 - val_accuracy: 0.2233\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.4737 - accuracy: 0.4029 - val_loss: 2.0263 - val_accuracy: 0.2267\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 289us/step - loss: 1.4739 - accuracy: 0.3971 - val_loss: 2.0206 - val_accuracy: 0.2467\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4732 - accuracy: 0.3986 - val_loss: 2.0255 - val_accuracy: 0.2433\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4727 - accuracy: 0.4000 - val_loss: 2.0425 - val_accuracy: 0.2267\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 262us/step - loss: 1.4734 - accuracy: 0.4014 - val_loss: 2.0394 - val_accuracy: 0.2300\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4741 - accuracy: 0.3957 - val_loss: 2.0433 - val_accuracy: 0.2267\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 305us/step - loss: 1.4706 - accuracy: 0.3929 - val_loss: 2.0516 - val_accuracy: 0.2500\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 319us/step - loss: 1.4740 - accuracy: 0.4000 - val_loss: 2.0528 - val_accuracy: 0.2267\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 297us/step - loss: 1.4727 - accuracy: 0.4043 - val_loss: 2.0387 - val_accuracy: 0.2300\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 443us/step - loss: 1.4718 - accuracy: 0.3957 - val_loss: 2.0482 - val_accuracy: 0.2400\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.4713 - accuracy: 0.4129 - val_loss: 2.0242 - val_accuracy: 0.2333\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.4725 - accuracy: 0.3986 - val_loss: 2.0523 - val_accuracy: 0.2267\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.4721 - accuracy: 0.3929 - val_loss: 2.0464 - val_accuracy: 0.2267\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 1.4711 - accuracy: 0.3986 - val_loss: 2.0381 - val_accuracy: 0.2333\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.4696 - accuracy: 0.4000 - val_loss: 2.0453 - val_accuracy: 0.2467\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.4711 - accuracy: 0.4029 - val_loss: 2.0409 - val_accuracy: 0.2267\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.4702 - accuracy: 0.3929 - val_loss: 2.0426 - val_accuracy: 0.2300\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 276us/step - loss: 1.4694 - accuracy: 0.4029 - val_loss: 2.0468 - val_accuracy: 0.2267\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4681 - accuracy: 0.3943 - val_loss: 2.0523 - val_accuracy: 0.2267\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 408us/step - loss: 1.4686 - accuracy: 0.4000 - val_loss: 2.0623 - val_accuracy: 0.2267\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4689 - accuracy: 0.3957 - val_loss: 2.0410 - val_accuracy: 0.2433\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s 259us/step - loss: 1.4690 - accuracy: 0.4014 - val_loss: 2.0542 - val_accuracy: 0.2433\n",
      "Epoch 533/1000\n",
      "700/700 [==============================] - 0s 283us/step - loss: 1.4685 - accuracy: 0.4000 - val_loss: 2.0491 - val_accuracy: 0.2300\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s 280us/step - loss: 1.4688 - accuracy: 0.3971 - val_loss: 2.0431 - val_accuracy: 0.2300\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.4673 - accuracy: 0.4043 - val_loss: 2.0739 - val_accuracy: 0.2433\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 163us/step - loss: 1.4671 - accuracy: 0.4043 - val_loss: 2.0705 - val_accuracy: 0.2267\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.4676 - accuracy: 0.4029 - val_loss: 2.0477 - val_accuracy: 0.2300\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 232us/step - loss: 1.4672 - accuracy: 0.3957 - val_loss: 2.0574 - val_accuracy: 0.2367\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 1.4691 - accuracy: 0.3943 - val_loss: 2.0508 - val_accuracy: 0.2267\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 1.4678 - accuracy: 0.4014 - val_loss: 2.0620 - val_accuracy: 0.2267\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.4667 - accuracy: 0.4014 - val_loss: 2.0590 - val_accuracy: 0.2267\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 1.4665 - accuracy: 0.4057 - val_loss: 2.0668 - val_accuracy: 0.2433\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 245us/step - loss: 1.4670 - accuracy: 0.4000 - val_loss: 2.0490 - val_accuracy: 0.2333\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4657 - accuracy: 0.3943 - val_loss: 2.0425 - val_accuracy: 0.2367\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 1.4665 - accuracy: 0.4014 - val_loss: 2.0537 - val_accuracy: 0.2300\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4635 - accuracy: 0.4000 - val_loss: 2.0713 - val_accuracy: 0.2533\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 327us/step - loss: 1.4657 - accuracy: 0.4000 - val_loss: 2.0779 - val_accuracy: 0.2400\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 368us/step - loss: 1.4643 - accuracy: 0.3971 - val_loss: 2.0494 - val_accuracy: 0.2300\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.4647 - accuracy: 0.4043 - val_loss: 2.0443 - val_accuracy: 0.2333\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 293us/step - loss: 1.4638 - accuracy: 0.4000 - val_loss: 2.0608 - val_accuracy: 0.2300\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.4647 - accuracy: 0.4000 - val_loss: 2.0584 - val_accuracy: 0.2300\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 256us/step - loss: 1.4632 - accuracy: 0.4086 - val_loss: 2.0582 - val_accuracy: 0.2333\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4654 - accuracy: 0.4000 - val_loss: 2.0563 - val_accuracy: 0.2300\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 295us/step - loss: 1.4630 - accuracy: 0.3986 - val_loss: 2.0678 - val_accuracy: 0.2300\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 373us/step - loss: 1.4637 - accuracy: 0.4057 - val_loss: 2.0700 - val_accuracy: 0.2400\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 1.4621 - accuracy: 0.4000 - val_loss: 2.0621 - val_accuracy: 0.2467\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4614 - accuracy: 0.4114 - val_loss: 2.0831 - val_accuracy: 0.2500\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4631 - accuracy: 0.4029 - val_loss: 2.0614 - val_accuracy: 0.2333\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.4614 - accuracy: 0.4029 - val_loss: 2.0657 - val_accuracy: 0.2533\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.4612 - accuracy: 0.4014 - val_loss: 2.0698 - val_accuracy: 0.2567\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.4623 - accuracy: 0.4100 - val_loss: 2.0637 - val_accuracy: 0.2267\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.4619 - accuracy: 0.4029 - val_loss: 2.0546 - val_accuracy: 0.2300\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 1.4613 - accuracy: 0.4000 - val_loss: 2.0600 - val_accuracy: 0.2267\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 1.4611 - accuracy: 0.4071 - val_loss: 2.0795 - val_accuracy: 0.2300\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 1.4603 - accuracy: 0.4043 - val_loss: 2.0619 - val_accuracy: 0.2333\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.4620 - accuracy: 0.4100 - val_loss: 2.0743 - val_accuracy: 0.2300\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 1.4599 - accuracy: 0.4171 - val_loss: 2.0782 - val_accuracy: 0.2300\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.4598 - accuracy: 0.4057 - val_loss: 2.0765 - val_accuracy: 0.2433\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 168us/step - loss: 1.4594 - accuracy: 0.4057 - val_loss: 2.0700 - val_accuracy: 0.2533\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 1.4586 - accuracy: 0.4114 - val_loss: 2.0794 - val_accuracy: 0.2333\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 1.4588 - accuracy: 0.4043 - val_loss: 2.0763 - val_accuracy: 0.2300\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 1.4580 - accuracy: 0.4014 - val_loss: 2.0652 - val_accuracy: 0.2333\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 1.4573 - accuracy: 0.4114 - val_loss: 2.0851 - val_accuracy: 0.2533\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4597 - accuracy: 0.4043 - val_loss: 2.0670 - val_accuracy: 0.2500\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 1.4597 - accuracy: 0.4114 - val_loss: 2.0723 - val_accuracy: 0.2267\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 1.4586 - accuracy: 0.3957 - val_loss: 2.0748 - val_accuracy: 0.2300\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.4583 - accuracy: 0.4014 - val_loss: 2.0725 - val_accuracy: 0.2300\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4577 - accuracy: 0.4071 - val_loss: 2.0727 - val_accuracy: 0.2367\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.4584 - accuracy: 0.4057 - val_loss: 2.0700 - val_accuracy: 0.2267\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.4574 - accuracy: 0.4086 - val_loss: 2.0834 - val_accuracy: 0.2367\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.4570 - accuracy: 0.4071 - val_loss: 2.0783 - val_accuracy: 0.2567\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 1.4569 - accuracy: 0.4071 - val_loss: 2.0819 - val_accuracy: 0.2267\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.4563 - accuracy: 0.4014 - val_loss: 2.0840 - val_accuracy: 0.2267\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 281us/step - loss: 1.4571 - accuracy: 0.4071 - val_loss: 2.0817 - val_accuracy: 0.2267\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.4558 - accuracy: 0.4100 - val_loss: 2.0865 - val_accuracy: 0.2300\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 1.4549 - accuracy: 0.4043 - val_loss: 2.0878 - val_accuracy: 0.2500\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 1.4573 - accuracy: 0.4114 - val_loss: 2.0871 - val_accuracy: 0.2333\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.4560 - accuracy: 0.4043 - val_loss: 2.0902 - val_accuracy: 0.2300\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 1.4553 - accuracy: 0.4057 - val_loss: 2.0906 - val_accuracy: 0.2267\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 1.4553 - accuracy: 0.4014 - val_loss: 2.0836 - val_accuracy: 0.2300\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.4554 - accuracy: 0.4086 - val_loss: 2.0946 - val_accuracy: 0.2267\n",
      "Epoch 592/1000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4544 - accuracy: 0.4086 - val_loss: 2.0885 - val_accuracy: 0.2333\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s 293us/step - loss: 1.4546 - accuracy: 0.4057 - val_loss: 2.0817 - val_accuracy: 0.2267\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.4540 - accuracy: 0.4129 - val_loss: 2.0828 - val_accuracy: 0.2333\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 296us/step - loss: 1.4543 - accuracy: 0.4057 - val_loss: 2.0905 - val_accuracy: 0.2433\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 232us/step - loss: 1.4537 - accuracy: 0.4129 - val_loss: 2.0782 - val_accuracy: 0.2300\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 1.4525 - accuracy: 0.4143 - val_loss: 2.0808 - val_accuracy: 0.2500\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 1.4537 - accuracy: 0.3986 - val_loss: 2.0903 - val_accuracy: 0.2267\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 1.4541 - accuracy: 0.4043 - val_loss: 2.0796 - val_accuracy: 0.2333\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 232us/step - loss: 1.4525 - accuracy: 0.4143 - val_loss: 2.0989 - val_accuracy: 0.2300\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s 225us/step - loss: 1.4523 - accuracy: 0.4129 - val_loss: 2.0981 - val_accuracy: 0.2433\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 1.4526 - accuracy: 0.4029 - val_loss: 2.0933 - val_accuracy: 0.2333\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 1.4527 - accuracy: 0.4114 - val_loss: 2.0824 - val_accuracy: 0.2400\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.4525 - accuracy: 0.4029 - val_loss: 2.0809 - val_accuracy: 0.2433\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.4516 - accuracy: 0.4057 - val_loss: 2.0888 - val_accuracy: 0.2367\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.4517 - accuracy: 0.4100 - val_loss: 2.0793 - val_accuracy: 0.2333\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 184us/step - loss: 1.4518 - accuracy: 0.4100 - val_loss: 2.0931 - val_accuracy: 0.2300\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 302us/step - loss: 1.4515 - accuracy: 0.4071 - val_loss: 2.0832 - val_accuracy: 0.2367\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 1.4500 - accuracy: 0.4157 - val_loss: 2.0998 - val_accuracy: 0.2567\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 1.4507 - accuracy: 0.4129 - val_loss: 2.1012 - val_accuracy: 0.2333\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 1.4508 - accuracy: 0.4129 - val_loss: 2.0975 - val_accuracy: 0.2367\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 1.4506 - accuracy: 0.4086 - val_loss: 2.0951 - val_accuracy: 0.2433\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.4505 - accuracy: 0.4086 - val_loss: 2.0964 - val_accuracy: 0.2300\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4496 - accuracy: 0.4129 - val_loss: 2.1080 - val_accuracy: 0.2500\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 313us/step - loss: 1.4502 - accuracy: 0.4129 - val_loss: 2.0887 - val_accuracy: 0.2533\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4495 - accuracy: 0.4129 - val_loss: 2.1144 - val_accuracy: 0.2333\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.4480 - accuracy: 0.4157 - val_loss: 2.1039 - val_accuracy: 0.2533\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.4491 - accuracy: 0.4014 - val_loss: 2.0963 - val_accuracy: 0.2400\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.4479 - accuracy: 0.4114 - val_loss: 2.1056 - val_accuracy: 0.2333\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4488 - accuracy: 0.4171 - val_loss: 2.0924 - val_accuracy: 0.2300\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 1.4487 - accuracy: 0.4129 - val_loss: 2.1158 - val_accuracy: 0.2333\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 1.4476 - accuracy: 0.4114 - val_loss: 2.1155 - val_accuracy: 0.2367\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 252us/step - loss: 1.4471 - accuracy: 0.4186 - val_loss: 2.1097 - val_accuracy: 0.2267\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.4480 - accuracy: 0.4171 - val_loss: 2.1088 - val_accuracy: 0.2367\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.4479 - accuracy: 0.4029 - val_loss: 2.1142 - val_accuracy: 0.2367\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 268us/step - loss: 1.4471 - accuracy: 0.4086 - val_loss: 2.0894 - val_accuracy: 0.2367\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 255us/step - loss: 1.4478 - accuracy: 0.4257 - val_loss: 2.1022 - val_accuracy: 0.2333\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 269us/step - loss: 1.4459 - accuracy: 0.4157 - val_loss: 2.0855 - val_accuracy: 0.2400\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4475 - accuracy: 0.4100 - val_loss: 2.1012 - val_accuracy: 0.2333\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 388us/step - loss: 1.4460 - accuracy: 0.4114 - val_loss: 2.0909 - val_accuracy: 0.2333\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 1.4468 - accuracy: 0.4114 - val_loss: 2.1271 - val_accuracy: 0.2400\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4467 - accuracy: 0.4086 - val_loss: 2.1177 - val_accuracy: 0.2400\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4455 - accuracy: 0.4143 - val_loss: 2.1269 - val_accuracy: 0.2367\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.4457 - accuracy: 0.4129 - val_loss: 2.1139 - val_accuracy: 0.2333\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 1.4444 - accuracy: 0.4071 - val_loss: 2.1061 - val_accuracy: 0.2567\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 265us/step - loss: 1.4463 - accuracy: 0.4129 - val_loss: 2.1088 - val_accuracy: 0.2333\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4451 - accuracy: 0.4114 - val_loss: 2.1212 - val_accuracy: 0.2367\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4452 - accuracy: 0.4114 - val_loss: 2.1277 - val_accuracy: 0.2300\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 1.4449 - accuracy: 0.4086 - val_loss: 2.1286 - val_accuracy: 0.2233\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 1.4441 - accuracy: 0.4157 - val_loss: 2.0973 - val_accuracy: 0.2367\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 1.4437 - accuracy: 0.4143 - val_loss: 2.1183 - val_accuracy: 0.2467\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.4448 - accuracy: 0.4100 - val_loss: 2.1281 - val_accuracy: 0.2433\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.4439 - accuracy: 0.4129 - val_loss: 2.1331 - val_accuracy: 0.2300\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.4440 - accuracy: 0.4129 - val_loss: 2.1148 - val_accuracy: 0.2367\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.4432 - accuracy: 0.4186 - val_loss: 2.1250 - val_accuracy: 0.2333\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4414 - accuracy: 0.4114 - val_loss: 2.1179 - val_accuracy: 0.2567\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.4423 - accuracy: 0.4114 - val_loss: 2.1133 - val_accuracy: 0.2367\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 1.4431 - accuracy: 0.4100 - val_loss: 2.1343 - val_accuracy: 0.2333\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.4415 - accuracy: 0.4057 - val_loss: 2.1301 - val_accuracy: 0.2333\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s 310us/step - loss: 1.4432 - accuracy: 0.4143 - val_loss: 2.1169 - val_accuracy: 0.2333\n",
      "Epoch 651/1000\n",
      "700/700 [==============================] - 0s 367us/step - loss: 1.4418 - accuracy: 0.4157 - val_loss: 2.1391 - val_accuracy: 0.2400\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s 327us/step - loss: 1.4430 - accuracy: 0.4114 - val_loss: 2.1186 - val_accuracy: 0.2333\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 280us/step - loss: 1.4415 - accuracy: 0.4171 - val_loss: 2.1247 - val_accuracy: 0.2433\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.4414 - accuracy: 0.4143 - val_loss: 2.1066 - val_accuracy: 0.2467\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 1.4406 - accuracy: 0.4100 - val_loss: 2.1201 - val_accuracy: 0.2533\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.4426 - accuracy: 0.4086 - val_loss: 2.1340 - val_accuracy: 0.2433\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.4409 - accuracy: 0.4186 - val_loss: 2.1286 - val_accuracy: 0.2300\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4409 - accuracy: 0.4143 - val_loss: 2.1242 - val_accuracy: 0.2367\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.4404 - accuracy: 0.4186 - val_loss: 2.1269 - val_accuracy: 0.2467\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 1.4409 - accuracy: 0.4100 - val_loss: 2.1270 - val_accuracy: 0.2367\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.4418 - accuracy: 0.4086 - val_loss: 2.1221 - val_accuracy: 0.2367\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 229us/step - loss: 1.4410 - accuracy: 0.4000 - val_loss: 2.1275 - val_accuracy: 0.2367\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 255us/step - loss: 1.4402 - accuracy: 0.4157 - val_loss: 2.1482 - val_accuracy: 0.2400\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 310us/step - loss: 1.4394 - accuracy: 0.4186 - val_loss: 2.1317 - val_accuracy: 0.2400\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4396 - accuracy: 0.4114 - val_loss: 2.1400 - val_accuracy: 0.2333\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 281us/step - loss: 1.4390 - accuracy: 0.4200 - val_loss: 2.1294 - val_accuracy: 0.2533\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.4406 - accuracy: 0.4114 - val_loss: 2.1217 - val_accuracy: 0.2367\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 252us/step - loss: 1.4375 - accuracy: 0.4157 - val_loss: 2.1405 - val_accuracy: 0.2567\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 263us/step - loss: 1.4382 - accuracy: 0.4157 - val_loss: 2.1450 - val_accuracy: 0.2333\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 249us/step - loss: 1.4393 - accuracy: 0.4171 - val_loss: 2.1303 - val_accuracy: 0.2333\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.4377 - accuracy: 0.4157 - val_loss: 2.1282 - val_accuracy: 0.2533\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.4382 - accuracy: 0.4100 - val_loss: 2.1405 - val_accuracy: 0.2367\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 1.4384 - accuracy: 0.4186 - val_loss: 2.1311 - val_accuracy: 0.2400\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 1.4374 - accuracy: 0.4086 - val_loss: 2.1580 - val_accuracy: 0.2433\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 163us/step - loss: 1.4366 - accuracy: 0.4214 - val_loss: 2.1570 - val_accuracy: 0.2533\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.4370 - accuracy: 0.4186 - val_loss: 2.1286 - val_accuracy: 0.2567\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 1.4360 - accuracy: 0.4143 - val_loss: 2.1505 - val_accuracy: 0.2300\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 1.4355 - accuracy: 0.4200 - val_loss: 2.1176 - val_accuracy: 0.2333\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 1.4369 - accuracy: 0.4257 - val_loss: 2.1406 - val_accuracy: 0.2367\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 1.4377 - accuracy: 0.4157 - val_loss: 2.1416 - val_accuracy: 0.2400\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.4370 - accuracy: 0.4186 - val_loss: 2.1307 - val_accuracy: 0.2400\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 1.4360 - accuracy: 0.4214 - val_loss: 2.1368 - val_accuracy: 0.2567\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 1.4356 - accuracy: 0.4129 - val_loss: 2.1275 - val_accuracy: 0.2500\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s 273us/step - loss: 1.4330 - accuracy: 0.4143 - val_loss: 2.1410 - val_accuracy: 0.2600\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s 245us/step - loss: 1.4356 - accuracy: 0.4143 - val_loss: 2.1360 - val_accuracy: 0.2567\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s 291us/step - loss: 1.4352 - accuracy: 0.4200 - val_loss: 2.1651 - val_accuracy: 0.2533\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 1.4354 - accuracy: 0.4143 - val_loss: 2.1270 - val_accuracy: 0.2367\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 1.4355 - accuracy: 0.4157 - val_loss: 2.1346 - val_accuracy: 0.2400\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 1.4348 - accuracy: 0.4200 - val_loss: 2.1469 - val_accuracy: 0.2367\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 1.4345 - accuracy: 0.4143 - val_loss: 2.1563 - val_accuracy: 0.2333\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s 315us/step - loss: 1.4337 - accuracy: 0.4229 - val_loss: 2.1496 - val_accuracy: 0.2333\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4339 - accuracy: 0.4186 - val_loss: 2.1345 - val_accuracy: 0.2400\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4345 - accuracy: 0.4171 - val_loss: 2.1337 - val_accuracy: 0.2400\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.4335 - accuracy: 0.4186 - val_loss: 2.1663 - val_accuracy: 0.2467\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 295us/step - loss: 1.4348 - accuracy: 0.4171 - val_loss: 2.1408 - val_accuracy: 0.2567\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s 400us/step - loss: 1.4324 - accuracy: 0.4214 - val_loss: 2.1548 - val_accuracy: 0.2333\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 1.4337 - accuracy: 0.4186 - val_loss: 2.1654 - val_accuracy: 0.2467\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 1.4333 - accuracy: 0.4257 - val_loss: 2.1511 - val_accuracy: 0.2433\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 1.4328 - accuracy: 0.4214 - val_loss: 2.1525 - val_accuracy: 0.2400\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 431us/step - loss: 1.4329 - accuracy: 0.4200 - val_loss: 2.1518 - val_accuracy: 0.2467\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 304us/step - loss: 1.4316 - accuracy: 0.4171 - val_loss: 2.1483 - val_accuracy: 0.2433\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 1.4327 - accuracy: 0.4129 - val_loss: 2.1556 - val_accuracy: 0.2367\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 1.4316 - accuracy: 0.4229 - val_loss: 2.1657 - val_accuracy: 0.2333\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 302us/step - loss: 1.4325 - accuracy: 0.4214 - val_loss: 2.1498 - val_accuracy: 0.2433\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 1.4320 - accuracy: 0.4157 - val_loss: 2.1429 - val_accuracy: 0.2400\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 239us/step - loss: 1.4321 - accuracy: 0.4214 - val_loss: 2.1335 - val_accuracy: 0.2400\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 1.4315 - accuracy: 0.4243 - val_loss: 2.1494 - val_accuracy: 0.2367\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 383us/step - loss: 1.4316 - accuracy: 0.4214 - val_loss: 2.1488 - val_accuracy: 0.2333\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s 294us/step - loss: 1.4296 - accuracy: 0.4186 - val_loss: 2.1794 - val_accuracy: 0.2533\n",
      "Epoch 710/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.4314 - accuracy: 0.4229 - val_loss: 2.1527 - val_accuracy: 0.2467\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s 423us/step - loss: 1.4304 - accuracy: 0.4186 - val_loss: 2.1542 - val_accuracy: 0.2367\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 418us/step - loss: 1.4300 - accuracy: 0.4214 - val_loss: 2.1636 - val_accuracy: 0.2567\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.4310 - accuracy: 0.4186 - val_loss: 2.1410 - val_accuracy: 0.2400\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 303us/step - loss: 1.4305 - accuracy: 0.4243 - val_loss: 2.1585 - val_accuracy: 0.2367\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.4282 - accuracy: 0.4243 - val_loss: 2.1502 - val_accuracy: 0.2600\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 1.4305 - accuracy: 0.4157 - val_loss: 2.1677 - val_accuracy: 0.2367\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 347us/step - loss: 1.4297 - accuracy: 0.4157 - val_loss: 2.1621 - val_accuracy: 0.2367\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 328us/step - loss: 1.4289 - accuracy: 0.4186 - val_loss: 2.1916 - val_accuracy: 0.2533\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.4303 - accuracy: 0.4186 - val_loss: 2.1728 - val_accuracy: 0.2400\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 1.4295 - accuracy: 0.4214 - val_loss: 2.1658 - val_accuracy: 0.2367\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 1.4291 - accuracy: 0.4200 - val_loss: 2.1649 - val_accuracy: 0.2433\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 1.4286 - accuracy: 0.4200 - val_loss: 2.1653 - val_accuracy: 0.2367\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 1.4282 - accuracy: 0.4214 - val_loss: 2.1490 - val_accuracy: 0.2400\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.4281 - accuracy: 0.4257 - val_loss: 2.1736 - val_accuracy: 0.2367\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 1.4277 - accuracy: 0.4229 - val_loss: 2.1819 - val_accuracy: 0.2433\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.4278 - accuracy: 0.4257 - val_loss: 2.1563 - val_accuracy: 0.2367\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 270us/step - loss: 1.4273 - accuracy: 0.4214 - val_loss: 2.1938 - val_accuracy: 0.2333\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 1.4276 - accuracy: 0.4200 - val_loss: 2.1558 - val_accuracy: 0.2400\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.4269 - accuracy: 0.4229 - val_loss: 2.1856 - val_accuracy: 0.2467\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 1.4269 - accuracy: 0.4257 - val_loss: 2.1927 - val_accuracy: 0.2400\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 282us/step - loss: 1.4277 - accuracy: 0.4143 - val_loss: 2.1736 - val_accuracy: 0.2367\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.4261 - accuracy: 0.4243 - val_loss: 2.1707 - val_accuracy: 0.2400\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 1.4263 - accuracy: 0.4286 - val_loss: 2.1618 - val_accuracy: 0.2400\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 308us/step - loss: 1.4271 - accuracy: 0.4214 - val_loss: 2.1844 - val_accuracy: 0.2400\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s 303us/step - loss: 1.4261 - accuracy: 0.4286 - val_loss: 2.1732 - val_accuracy: 0.2367\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 289us/step - loss: 1.4249 - accuracy: 0.4300 - val_loss: 2.1629 - val_accuracy: 0.2400\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 322us/step - loss: 1.4265 - accuracy: 0.4229 - val_loss: 2.1866 - val_accuracy: 0.2433\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.4265 - accuracy: 0.4200 - val_loss: 2.1722 - val_accuracy: 0.2467\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4251 - accuracy: 0.4271 - val_loss: 2.1827 - val_accuracy: 0.2367\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 314us/step - loss: 1.4250 - accuracy: 0.4314 - val_loss: 2.1680 - val_accuracy: 0.2400\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 398us/step - loss: 1.4249 - accuracy: 0.4200 - val_loss: 2.1864 - val_accuracy: 0.2567\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.4252 - accuracy: 0.4143 - val_loss: 2.1628 - val_accuracy: 0.2533\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 232us/step - loss: 1.4240 - accuracy: 0.4286 - val_loss: 2.1670 - val_accuracy: 0.2533\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 1.4257 - accuracy: 0.4186 - val_loss: 2.1682 - val_accuracy: 0.2433\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.4221 - accuracy: 0.4329 - val_loss: 2.1818 - val_accuracy: 0.2533\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.4254 - accuracy: 0.4300 - val_loss: 2.1702 - val_accuracy: 0.2400\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 1.4251 - accuracy: 0.4157 - val_loss: 2.1784 - val_accuracy: 0.2433\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4233 - accuracy: 0.4257 - val_loss: 2.2001 - val_accuracy: 0.2600\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 1.4222 - accuracy: 0.4271 - val_loss: 2.1563 - val_accuracy: 0.2333\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.4239 - accuracy: 0.4329 - val_loss: 2.1629 - val_accuracy: 0.2300\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.4224 - accuracy: 0.4171 - val_loss: 2.1794 - val_accuracy: 0.2400\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 298us/step - loss: 1.4233 - accuracy: 0.4243 - val_loss: 2.1854 - val_accuracy: 0.2367\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 269us/step - loss: 1.4223 - accuracy: 0.4257 - val_loss: 2.2051 - val_accuracy: 0.2333\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 346us/step - loss: 1.4235 - accuracy: 0.4271 - val_loss: 2.1869 - val_accuracy: 0.2333\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.4221 - accuracy: 0.4386 - val_loss: 2.1849 - val_accuracy: 0.2467\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 1.4223 - accuracy: 0.4143 - val_loss: 2.1829 - val_accuracy: 0.2400\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4233 - accuracy: 0.4200 - val_loss: 2.1907 - val_accuracy: 0.2433\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 1.4220 - accuracy: 0.4300 - val_loss: 2.1885 - val_accuracy: 0.2433\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4221 - accuracy: 0.4271 - val_loss: 2.1786 - val_accuracy: 0.2400\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 1.4218 - accuracy: 0.4329 - val_loss: 2.1784 - val_accuracy: 0.2400\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.4215 - accuracy: 0.4229 - val_loss: 2.2086 - val_accuracy: 0.2500\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 252us/step - loss: 1.4225 - accuracy: 0.4257 - val_loss: 2.1981 - val_accuracy: 0.2400\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 1.4215 - accuracy: 0.4200 - val_loss: 2.1838 - val_accuracy: 0.2400\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 316us/step - loss: 1.4227 - accuracy: 0.4300 - val_loss: 2.2048 - val_accuracy: 0.2433\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 249us/step - loss: 1.4203 - accuracy: 0.4214 - val_loss: 2.2158 - val_accuracy: 0.2333\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.4217 - accuracy: 0.4214 - val_loss: 2.1842 - val_accuracy: 0.2400\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 1.4217 - accuracy: 0.4257 - val_loss: 2.1846 - val_accuracy: 0.2367\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 1.4205 - accuracy: 0.4257 - val_loss: 2.1738 - val_accuracy: 0.2400\n",
      "Epoch 769/1000\n",
      "700/700 [==============================] - 0s 281us/step - loss: 1.4207 - accuracy: 0.4243 - val_loss: 2.1856 - val_accuracy: 0.2367\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 1.4200 - accuracy: 0.4214 - val_loss: 2.1758 - val_accuracy: 0.2333\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 276us/step - loss: 1.4196 - accuracy: 0.4214 - val_loss: 2.1942 - val_accuracy: 0.2367\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 228us/step - loss: 1.4202 - accuracy: 0.4229 - val_loss: 2.1983 - val_accuracy: 0.2433\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.4200 - accuracy: 0.4229 - val_loss: 2.2066 - val_accuracy: 0.2500\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.4191 - accuracy: 0.4243 - val_loss: 2.2019 - val_accuracy: 0.2400\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.4182 - accuracy: 0.4286 - val_loss: 2.2032 - val_accuracy: 0.2533\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.4193 - accuracy: 0.4271 - val_loss: 2.1977 - val_accuracy: 0.2467\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 1.4177 - accuracy: 0.4314 - val_loss: 2.2090 - val_accuracy: 0.2333\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 1.4190 - accuracy: 0.4214 - val_loss: 2.1922 - val_accuracy: 0.2333\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.4191 - accuracy: 0.4300 - val_loss: 2.1962 - val_accuracy: 0.2333\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 1.4190 - accuracy: 0.4229 - val_loss: 2.1879 - val_accuracy: 0.2400\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4196 - accuracy: 0.4214 - val_loss: 2.1973 - val_accuracy: 0.2467\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 242us/step - loss: 1.4184 - accuracy: 0.4257 - val_loss: 2.1738 - val_accuracy: 0.2400\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4143 - accuracy: 0.43 - 0s 190us/step - loss: 1.4186 - accuracy: 0.4329 - val_loss: 2.2047 - val_accuracy: 0.2433\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 1.4181 - accuracy: 0.4300 - val_loss: 2.2132 - val_accuracy: 0.2400\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 1.4179 - accuracy: 0.4271 - val_loss: 2.2198 - val_accuracy: 0.2367\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 1.4180 - accuracy: 0.4271 - val_loss: 2.1994 - val_accuracy: 0.2467\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 1.4184 - accuracy: 0.4243 - val_loss: 2.1838 - val_accuracy: 0.2500\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.4178 - accuracy: 0.4271 - val_loss: 2.1991 - val_accuracy: 0.2400\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 1.4173 - accuracy: 0.4229 - val_loss: 2.1994 - val_accuracy: 0.2400\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 1.4174 - accuracy: 0.4314 - val_loss: 2.2033 - val_accuracy: 0.2400\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.4164 - accuracy: 0.4286 - val_loss: 2.2056 - val_accuracy: 0.2500\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.4171 - accuracy: 0.4229 - val_loss: 2.1936 - val_accuracy: 0.2367\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 1.4166 - accuracy: 0.4257 - val_loss: 2.2141 - val_accuracy: 0.2500\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 225us/step - loss: 1.4169 - accuracy: 0.4271 - val_loss: 2.2061 - val_accuracy: 0.2367\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 1.4164 - accuracy: 0.4314 - val_loss: 2.2030 - val_accuracy: 0.2400\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 1.4160 - accuracy: 0.4300 - val_loss: 2.2047 - val_accuracy: 0.2367\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 1.4164 - accuracy: 0.4200 - val_loss: 2.2128 - val_accuracy: 0.2367\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 181us/step - loss: 1.4162 - accuracy: 0.4386 - val_loss: 2.2137 - val_accuracy: 0.2400\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 1.4152 - accuracy: 0.4329 - val_loss: 2.2049 - val_accuracy: 0.2567\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.4159 - accuracy: 0.4200 - val_loss: 2.2158 - val_accuracy: 0.2333\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.4159 - accuracy: 0.4329 - val_loss: 2.2122 - val_accuracy: 0.2333\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 1.4158 - accuracy: 0.4329 - val_loss: 2.2595 - val_accuracy: 0.2400\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 1.4146 - accuracy: 0.4271 - val_loss: 2.2121 - val_accuracy: 0.2600\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 181us/step - loss: 1.4148 - accuracy: 0.4243 - val_loss: 2.2039 - val_accuracy: 0.2433\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3700 - accuracy: 0.42 - 0s 179us/step - loss: 1.4143 - accuracy: 0.4329 - val_loss: 2.2054 - val_accuracy: 0.2467\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 1.4148 - accuracy: 0.4357 - val_loss: 2.2052 - val_accuracy: 0.2400\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 270us/step - loss: 1.4148 - accuracy: 0.4386 - val_loss: 2.2125 - val_accuracy: 0.2500\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 1.4143 - accuracy: 0.4314 - val_loss: 2.2125 - val_accuracy: 0.2400\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 1.4150 - accuracy: 0.4229 - val_loss: 2.2137 - val_accuracy: 0.2467\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 1.4139 - accuracy: 0.4357 - val_loss: 2.2157 - val_accuracy: 0.2367\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 285us/step - loss: 1.4142 - accuracy: 0.4314 - val_loss: 2.2169 - val_accuracy: 0.2400\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.4141 - accuracy: 0.4271 - val_loss: 2.2032 - val_accuracy: 0.2400\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 1.4139 - accuracy: 0.4329 - val_loss: 2.2245 - val_accuracy: 0.2400\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 1.4131 - accuracy: 0.4286 - val_loss: 2.2157 - val_accuracy: 0.2533\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.4139 - accuracy: 0.4314 - val_loss: 2.2224 - val_accuracy: 0.2467\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 1.4136 - accuracy: 0.4300 - val_loss: 2.2146 - val_accuracy: 0.2367\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.4116 - accuracy: 0.4300 - val_loss: 2.2146 - val_accuracy: 0.2367\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 1.4123 - accuracy: 0.4286 - val_loss: 2.2243 - val_accuracy: 0.2367\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.4110 - accuracy: 0.4357 - val_loss: 2.2386 - val_accuracy: 0.2600\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 1.4131 - accuracy: 0.4329 - val_loss: 2.2190 - val_accuracy: 0.2567\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 1.4129 - accuracy: 0.4300 - val_loss: 2.2348 - val_accuracy: 0.2467\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.4130 - accuracy: 0.4329 - val_loss: 2.2198 - val_accuracy: 0.2367\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 1.4114 - accuracy: 0.4271 - val_loss: 2.2264 - val_accuracy: 0.2433\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.4110 - accuracy: 0.4300 - val_loss: 2.2265 - val_accuracy: 0.2433\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 1.4112 - accuracy: 0.4314 - val_loss: 2.2452 - val_accuracy: 0.2467\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.4122 - accuracy: 0.4271 - val_loss: 2.2332 - val_accuracy: 0.2467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.4112 - accuracy: 0.4300 - val_loss: 2.2318 - val_accuracy: 0.2400\n",
      "Epoch 828/1000\n",
      "700/700 [==============================] - 0s 279us/step - loss: 1.4118 - accuracy: 0.4343 - val_loss: 2.2184 - val_accuracy: 0.2367\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 1.4111 - accuracy: 0.4314 - val_loss: 2.2233 - val_accuracy: 0.2433\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.4104 - accuracy: 0.4271 - val_loss: 2.2284 - val_accuracy: 0.2400\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 1.4105 - accuracy: 0.4443 - val_loss: 2.2469 - val_accuracy: 0.2467\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.4111 - accuracy: 0.4343 - val_loss: 2.2477 - val_accuracy: 0.2500\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 1.4110 - accuracy: 0.4243 - val_loss: 2.2534 - val_accuracy: 0.2467\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 1.4106 - accuracy: 0.4329 - val_loss: 2.2659 - val_accuracy: 0.2433\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.4095 - accuracy: 0.4300 - val_loss: 2.2260 - val_accuracy: 0.2367\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4098 - accuracy: 0.4271 - val_loss: 2.2383 - val_accuracy: 0.2500\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.4102 - accuracy: 0.4300 - val_loss: 2.2211 - val_accuracy: 0.2433\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4107 - accuracy: 0.4329 - val_loss: 2.2368 - val_accuracy: 0.2367\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 1.4088 - accuracy: 0.4300 - val_loss: 2.2353 - val_accuracy: 0.2367\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 1.4081 - accuracy: 0.4343 - val_loss: 2.2224 - val_accuracy: 0.2433\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.4092 - accuracy: 0.4371 - val_loss: 2.2331 - val_accuracy: 0.2367\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.4098 - accuracy: 0.4271 - val_loss: 2.2487 - val_accuracy: 0.2500\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.4090 - accuracy: 0.4314 - val_loss: 2.2326 - val_accuracy: 0.2367\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 1.4082 - accuracy: 0.4300 - val_loss: 2.2510 - val_accuracy: 0.2367\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4088 - accuracy: 0.4314 - val_loss: 2.2242 - val_accuracy: 0.2367\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.4092 - accuracy: 0.4357 - val_loss: 2.2349 - val_accuracy: 0.2400\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4075 - accuracy: 0.4229 - val_loss: 2.2487 - val_accuracy: 0.2433\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 242us/step - loss: 1.4079 - accuracy: 0.4371 - val_loss: 2.2414 - val_accuracy: 0.2533\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 1.4086 - accuracy: 0.4300 - val_loss: 2.2446 - val_accuracy: 0.2433\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 1.4071 - accuracy: 0.4314 - val_loss: 2.2355 - val_accuracy: 0.2367\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.4071 - accuracy: 0.4229 - val_loss: 2.2345 - val_accuracy: 0.2333\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.4086 - accuracy: 0.4371 - val_loss: 2.2389 - val_accuracy: 0.2433\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.4066 - accuracy: 0.4329 - val_loss: 2.2368 - val_accuracy: 0.2367\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 1.4046 - accuracy: 0.4371 - val_loss: 2.2682 - val_accuracy: 0.2600\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 1.4074 - accuracy: 0.4271 - val_loss: 2.2383 - val_accuracy: 0.2333\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4074 - accuracy: 0.4357 - val_loss: 2.2498 - val_accuracy: 0.2500\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 1.4067 - accuracy: 0.4286 - val_loss: 2.2486 - val_accuracy: 0.2467\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.4066 - accuracy: 0.4343 - val_loss: 2.2459 - val_accuracy: 0.2367\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 263us/step - loss: 1.4052 - accuracy: 0.4357 - val_loss: 2.2438 - val_accuracy: 0.2367\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.4057 - accuracy: 0.4357 - val_loss: 2.2736 - val_accuracy: 0.2533\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.4064 - accuracy: 0.4343 - val_loss: 2.2575 - val_accuracy: 0.2433\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 255us/step - loss: 1.4071 - accuracy: 0.4271 - val_loss: 2.2603 - val_accuracy: 0.2533\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 346us/step - loss: 1.4055 - accuracy: 0.4329 - val_loss: 2.2607 - val_accuracy: 0.2500\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 334us/step - loss: 1.4053 - accuracy: 0.4329 - val_loss: 2.2554 - val_accuracy: 0.2533\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 274us/step - loss: 1.4047 - accuracy: 0.4386 - val_loss: 2.2618 - val_accuracy: 0.2633\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 277us/step - loss: 1.4049 - accuracy: 0.4314 - val_loss: 2.2232 - val_accuracy: 0.2433\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 278us/step - loss: 1.4052 - accuracy: 0.4357 - val_loss: 2.2613 - val_accuracy: 0.2433\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 242us/step - loss: 1.4054 - accuracy: 0.4357 - val_loss: 2.2531 - val_accuracy: 0.2467\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 292us/step - loss: 1.4050 - accuracy: 0.4386 - val_loss: 2.2509 - val_accuracy: 0.2400\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4034 - accuracy: 0.4357 - val_loss: 2.2675 - val_accuracy: 0.2467\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 1.4048 - accuracy: 0.4314 - val_loss: 2.2729 - val_accuracy: 0.2467\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4037 - accuracy: 0.4357 - val_loss: 2.2533 - val_accuracy: 0.2567\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s 256us/step - loss: 1.4042 - accuracy: 0.4343 - val_loss: 2.2292 - val_accuracy: 0.2367\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.4048 - accuracy: 0.4329 - val_loss: 2.2420 - val_accuracy: 0.2367\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4038 - accuracy: 0.4329 - val_loss: 2.2705 - val_accuracy: 0.2467\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.4035 - accuracy: 0.4314 - val_loss: 2.2423 - val_accuracy: 0.2433\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.4037 - accuracy: 0.4271 - val_loss: 2.2683 - val_accuracy: 0.2367\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.4042 - accuracy: 0.4343 - val_loss: 2.2634 - val_accuracy: 0.2400\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.4012 - accuracy: 0.4371 - val_loss: 2.2625 - val_accuracy: 0.2400\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 306us/step - loss: 1.4051 - accuracy: 0.4329 - val_loss: 2.2507 - val_accuracy: 0.2400\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 328us/step - loss: 1.4035 - accuracy: 0.4429 - val_loss: 2.2849 - val_accuracy: 0.2500\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 298us/step - loss: 1.4035 - accuracy: 0.4371 - val_loss: 2.2680 - val_accuracy: 0.2400\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 296us/step - loss: 1.4044 - accuracy: 0.4286 - val_loss: 2.2364 - val_accuracy: 0.2400\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 266us/step - loss: 1.4027 - accuracy: 0.4314 - val_loss: 2.2784 - val_accuracy: 0.2533\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.4031 - accuracy: 0.4314 - val_loss: 2.2322 - val_accuracy: 0.2433\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.4036 - accuracy: 0.4386 - val_loss: 2.2614 - val_accuracy: 0.2467\n",
      "Epoch 887/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.4026 - accuracy: 0.4371 - val_loss: 2.2456 - val_accuracy: 0.2367\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 1.4027 - accuracy: 0.4357 - val_loss: 2.2595 - val_accuracy: 0.2400\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 1.4010 - accuracy: 0.4443 - val_loss: 2.2736 - val_accuracy: 0.2600\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 225us/step - loss: 1.4028 - accuracy: 0.4386 - val_loss: 2.2630 - val_accuracy: 0.2567\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 1.4024 - accuracy: 0.4271 - val_loss: 2.2669 - val_accuracy: 0.2433\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 262us/step - loss: 1.4024 - accuracy: 0.4357 - val_loss: 2.2699 - val_accuracy: 0.2433\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4018 - accuracy: 0.4357 - val_loss: 2.2777 - val_accuracy: 0.2433\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.4020 - accuracy: 0.4429 - val_loss: 2.2620 - val_accuracy: 0.2400\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.4012 - accuracy: 0.4343 - val_loss: 2.2655 - val_accuracy: 0.2467\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.4014 - accuracy: 0.4357 - val_loss: 2.2715 - val_accuracy: 0.2600\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 245us/step - loss: 1.4017 - accuracy: 0.4343 - val_loss: 2.2648 - val_accuracy: 0.2533\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.4011 - accuracy: 0.4386 - val_loss: 2.2896 - val_accuracy: 0.2467\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.4015 - accuracy: 0.4343 - val_loss: 2.2583 - val_accuracy: 0.2467\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 1.4001 - accuracy: 0.4471 - val_loss: 2.2617 - val_accuracy: 0.2467\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 1.3999 - accuracy: 0.4400 - val_loss: 2.2772 - val_accuracy: 0.2533\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4001 - accuracy: 0.4343 - val_loss: 2.2689 - val_accuracy: 0.2467\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 1.3992 - accuracy: 0.4414 - val_loss: 2.2865 - val_accuracy: 0.2633\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 1.3991 - accuracy: 0.4357 - val_loss: 2.2582 - val_accuracy: 0.2400\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4010 - accuracy: 0.4400 - val_loss: 2.2543 - val_accuracy: 0.2400\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 293us/step - loss: 1.3998 - accuracy: 0.4371 - val_loss: 2.2494 - val_accuracy: 0.2367\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 1.4003 - accuracy: 0.4386 - val_loss: 2.2830 - val_accuracy: 0.2467\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.3997 - accuracy: 0.4414 - val_loss: 2.2715 - val_accuracy: 0.2433\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.3993 - accuracy: 0.4329 - val_loss: 2.2790 - val_accuracy: 0.2500\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 376us/step - loss: 1.4004 - accuracy: 0.4357 - val_loss: 2.2561 - val_accuracy: 0.2400\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.3991 - accuracy: 0.4371 - val_loss: 2.2786 - val_accuracy: 0.2367\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3995 - accuracy: 0.4400 - val_loss: 2.2665 - val_accuracy: 0.2367\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4000 - accuracy: 0.4371 - val_loss: 2.2924 - val_accuracy: 0.2433\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 1.3988 - accuracy: 0.4386 - val_loss: 2.2909 - val_accuracy: 0.2567\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 1.3990 - accuracy: 0.4343 - val_loss: 2.2737 - val_accuracy: 0.2467\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 268us/step - loss: 1.3987 - accuracy: 0.4386 - val_loss: 2.2810 - val_accuracy: 0.2400\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.3978 - accuracy: 0.4400 - val_loss: 2.2807 - val_accuracy: 0.2400\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 1.3970 - accuracy: 0.4386 - val_loss: 2.2802 - val_accuracy: 0.2533\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3984 - accuracy: 0.4329 - val_loss: 2.2901 - val_accuracy: 0.2433\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3988 - accuracy: 0.4343 - val_loss: 2.2681 - val_accuracy: 0.2500\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 315us/step - loss: 1.3984 - accuracy: 0.4357 - val_loss: 2.2706 - val_accuracy: 0.2400\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3967 - accuracy: 0.4400 - val_loss: 2.2872 - val_accuracy: 0.2500\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.3966 - accuracy: 0.4386 - val_loss: 2.2698 - val_accuracy: 0.2567\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 290us/step - loss: 1.3988 - accuracy: 0.4414 - val_loss: 2.2782 - val_accuracy: 0.2467\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 445us/step - loss: 1.3970 - accuracy: 0.4343 - val_loss: 2.2855 - val_accuracy: 0.2367\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3972 - accuracy: 0.4443 - val_loss: 2.2793 - val_accuracy: 0.2467\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 1.3975 - accuracy: 0.4357 - val_loss: 2.2798 - val_accuracy: 0.2400\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3971 - accuracy: 0.4400 - val_loss: 2.3013 - val_accuracy: 0.2433\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.3971 - accuracy: 0.4414 - val_loss: 2.2997 - val_accuracy: 0.2400\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3971 - accuracy: 0.4357 - val_loss: 2.2816 - val_accuracy: 0.2467\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.3967 - accuracy: 0.4329 - val_loss: 2.2836 - val_accuracy: 0.2467\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.3962 - accuracy: 0.4400 - val_loss: 2.2720 - val_accuracy: 0.2500\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.3966 - accuracy: 0.4314 - val_loss: 2.2861 - val_accuracy: 0.2467\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 1.3958 - accuracy: 0.4414 - val_loss: 2.2939 - val_accuracy: 0.2500\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 287us/step - loss: 1.3966 - accuracy: 0.4414 - val_loss: 2.2901 - val_accuracy: 0.2500\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 267us/step - loss: 1.3965 - accuracy: 0.4429 - val_loss: 2.2962 - val_accuracy: 0.2500\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 348us/step - loss: 1.3960 - accuracy: 0.4400 - val_loss: 2.2877 - val_accuracy: 0.2367\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 259us/step - loss: 1.3953 - accuracy: 0.4443 - val_loss: 2.2991 - val_accuracy: 0.2500\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 1.3953 - accuracy: 0.4386 - val_loss: 2.3114 - val_accuracy: 0.2500\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 1.3960 - accuracy: 0.4343 - val_loss: 2.2826 - val_accuracy: 0.2400\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 1.3957 - accuracy: 0.4343 - val_loss: 2.2917 - val_accuracy: 0.2400\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.3947 - accuracy: 0.4357 - val_loss: 2.2695 - val_accuracy: 0.2333\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 166us/step - loss: 1.3955 - accuracy: 0.4414 - val_loss: 2.3028 - val_accuracy: 0.2433\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.3944 - accuracy: 0.4371 - val_loss: 2.3057 - val_accuracy: 0.2433\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 1.3947 - accuracy: 0.4329 - val_loss: 2.3010 - val_accuracy: 0.2500\n",
      "Epoch 946/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 1.3945 - accuracy: 0.4329 - val_loss: 2.2912 - val_accuracy: 0.2467\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 1.3939 - accuracy: 0.4414 - val_loss: 2.3067 - val_accuracy: 0.2533\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 267us/step - loss: 1.3940 - accuracy: 0.4300 - val_loss: 2.2777 - val_accuracy: 0.2367\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3938 - accuracy: 0.4471 - val_loss: 2.2906 - val_accuracy: 0.2400\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 1.3929 - accuracy: 0.4386 - val_loss: 2.2916 - val_accuracy: 0.2367\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.3940 - accuracy: 0.4429 - val_loss: 2.3014 - val_accuracy: 0.2500\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 168us/step - loss: 1.3938 - accuracy: 0.4414 - val_loss: 2.2949 - val_accuracy: 0.2467\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 1.3935 - accuracy: 0.4371 - val_loss: 2.3148 - val_accuracy: 0.2533\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 1.3940 - accuracy: 0.4471 - val_loss: 2.2962 - val_accuracy: 0.2567\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 1.3936 - accuracy: 0.4429 - val_loss: 2.3098 - val_accuracy: 0.2500\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 1.3928 - accuracy: 0.4386 - val_loss: 2.3181 - val_accuracy: 0.2433\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 1.3925 - accuracy: 0.4414 - val_loss: 2.2925 - val_accuracy: 0.2433\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 1.3938 - accuracy: 0.4343 - val_loss: 2.3365 - val_accuracy: 0.2467\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 1.3936 - accuracy: 0.4414 - val_loss: 2.2892 - val_accuracy: 0.2467\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 1.3930 - accuracy: 0.4400 - val_loss: 2.3049 - val_accuracy: 0.2467\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 1.3923 - accuracy: 0.4429 - val_loss: 2.2714 - val_accuracy: 0.2467\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 1.3931 - accuracy: 0.4400 - val_loss: 2.3025 - val_accuracy: 0.2467\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.3926 - accuracy: 0.4386 - val_loss: 2.2963 - val_accuracy: 0.2500\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3919 - accuracy: 0.4357 - val_loss: 2.2856 - val_accuracy: 0.2433\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.3913 - accuracy: 0.4414 - val_loss: 2.2959 - val_accuracy: 0.2533\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 1.3924 - accuracy: 0.4429 - val_loss: 2.3148 - val_accuracy: 0.2567\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 1.3923 - accuracy: 0.4429 - val_loss: 2.3105 - val_accuracy: 0.2467\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.3913 - accuracy: 0.4400 - val_loss: 2.2989 - val_accuracy: 0.2433\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3917 - accuracy: 0.4414 - val_loss: 2.3052 - val_accuracy: 0.2433\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 1.3916 - accuracy: 0.4400 - val_loss: 2.3201 - val_accuracy: 0.2400\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 1.3916 - accuracy: 0.4414 - val_loss: 2.3001 - val_accuracy: 0.2467\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3913 - accuracy: 0.4386 - val_loss: 2.3213 - val_accuracy: 0.2333\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.3901 - accuracy: 0.4400 - val_loss: 2.3114 - val_accuracy: 0.2500\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 1.3908 - accuracy: 0.4386 - val_loss: 2.3123 - val_accuracy: 0.2500\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 1.3907 - accuracy: 0.4443 - val_loss: 2.3262 - val_accuracy: 0.2500\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3905 - accuracy: 0.4429 - val_loss: 2.3076 - val_accuracy: 0.2500\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 306us/step - loss: 1.3905 - accuracy: 0.4343 - val_loss: 2.3044 - val_accuracy: 0.2400\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3904 - accuracy: 0.4486 - val_loss: 2.3117 - val_accuracy: 0.2533\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 318us/step - loss: 1.3906 - accuracy: 0.4429 - val_loss: 2.3081 - val_accuracy: 0.2467\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.3906 - accuracy: 0.4429 - val_loss: 2.3256 - val_accuracy: 0.2500\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3894 - accuracy: 0.4371 - val_loss: 2.3378 - val_accuracy: 0.2500\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 1.3902 - accuracy: 0.4400 - val_loss: 2.3157 - val_accuracy: 0.2533\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 265us/step - loss: 1.3897 - accuracy: 0.4357 - val_loss: 2.3231 - val_accuracy: 0.2500\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 271us/step - loss: 1.3898 - accuracy: 0.4414 - val_loss: 2.3133 - val_accuracy: 0.2500\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.3891 - accuracy: 0.4400 - val_loss: 2.3245 - val_accuracy: 0.2367\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 414us/step - loss: 1.3891 - accuracy: 0.4414 - val_loss: 2.3228 - val_accuracy: 0.2500\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.3887 - accuracy: 0.4414 - val_loss: 2.3043 - val_accuracy: 0.2400\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 299us/step - loss: 1.3886 - accuracy: 0.4429 - val_loss: 2.3385 - val_accuracy: 0.2633\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 1.3903 - accuracy: 0.4357 - val_loss: 2.3375 - val_accuracy: 0.2533\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3887 - accuracy: 0.4443 - val_loss: 2.3547 - val_accuracy: 0.2533\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3890 - accuracy: 0.4471 - val_loss: 2.3138 - val_accuracy: 0.2433\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 213us/step - loss: 1.3888 - accuracy: 0.4371 - val_loss: 2.3301 - val_accuracy: 0.2400\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.3885 - accuracy: 0.4457 - val_loss: 2.3353 - val_accuracy: 0.2533\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 1.3885 - accuracy: 0.4357 - val_loss: 2.3073 - val_accuracy: 0.2367\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 1.3890 - accuracy: 0.4429 - val_loss: 2.3282 - val_accuracy: 0.2500\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 232us/step - loss: 1.3877 - accuracy: 0.4457 - val_loss: 2.3284 - val_accuracy: 0.2467\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.3879 - accuracy: 0.4429 - val_loss: 2.3277 - val_accuracy: 0.2533\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3887 - accuracy: 0.4386 - val_loss: 2.3401 - val_accuracy: 0.2533\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 1.3881 - accuracy: 0.4386 - val_loss: 2.3246 - val_accuracy: 0.2500\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.3879 - accuracy: 0.4386 - val_loss: 2.3363 - val_accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 모델 학습 과정 표시하기\n",
    "print(hist.history.keys())\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vdsr] *",
   "language": "python",
   "name": "conda-env-vdsr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
